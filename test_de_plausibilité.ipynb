{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OcBwaujqj7wg"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Ce programme a pour but de tester la plausibilité de la prononciation d'un mot telle qu'indiquée sur le Wiktionnaire.\n",
    "\n",
    "Pour ce faire, il parcours itérativement les différents sons (phonemes) d'un mot et essaie les différentes lettres (graphemes) pouvant être utilisées pour écrire le son (grâce à une table de correspondance similaire à https://fr.wiktionary.org/wiki/Annexe:Prononciation/français#Troisième_approche). A chaque essai, il compare ce qu'il obtient avec l'orthographe utilisée dans le Wiktionnaire. Lorsqu'il arrive au même résultat, la prononciation du mot est jugée plausible. A l'inverse, s'il n'arrive pas à transcrire la même orthographe que celle indiquée dans le Wiktionnaire, la prononciation est jugée suspecte.\n",
    "\n",
    "Ce programme peut aussi compter les différentes lettres utilisées pour transcrire un son. Ainsi, s'il est executé sur tous les mots du Wiktionnaire, il peut servir à compter les probabilités de ces lettres pour transcrire un son donné.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8iczXUEW6x1g"
   },
   "source": [
    "## Données d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zD26Opi6hhPK"
   },
   "outputs": [],
   "source": [
    "# importation des librairies tierces\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# lecture des données d'entrée (ligne contenant un mot du dictionnaire\n",
    "# ainsi que sa prononciation\n",
    "def read_df():\n",
    "\n",
    "  '''Read the input data (i.e. lines containing a Wiktionary word \n",
    "  and its pronunciation) '''\n",
    "  filename = '../wikt_parser/fr_wiktionary_full.csv'\n",
    "  #filename = '../wikt_parser/fr_wiktionary_waves.csv'\n",
    "    \n",
    "  filepath = Path(filename)\n",
    "\n",
    "  url = 'https://fonétik.fr/'\n",
    "  url_filename = url + filename\n",
    "\n",
    "  #print('downloading ', url_filename)\n",
    "  # if file not found locally, then download it\n",
    "  #if not filepath.exists():\n",
    "  #  !wget -N -q {url_filename}\n",
    "\n",
    "  df = pd.read_csv(filename, keep_default_na=False, sep = '\\t')\n",
    "\n",
    "  return df\n",
    "\n",
    "df = read_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "e8LX-nHWXKQg",
    "outputId": "3d969ca8-f285-451a-cf15-4ff81bdd3c6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audio</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1503702</td>\n",
       "      <td>’tit</td>\n",
       "      <td>ti</td>\n",
       "      <td>False</td>\n",
       "      <td>adjectif</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1503703</td>\n",
       "      <td>’upa’upa</td>\n",
       "      <td>u.pa.u.pa</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1503704</td>\n",
       "      <td>€</td>\n",
       "      <td>ø.ʁo</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>€_as_first_letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1503705</td>\n",
       "      <td>℁</td>\n",
       "      <td>o bɔ̃ swɛ̃ də</td>\n",
       "      <td>False</td>\n",
       "      <td>préposition</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>℁_as_first_letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1503706</td>\n",
       "      <td>∴</td>\n",
       "      <td>mɔʁ‿o.vaʃ</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole_num=2</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>∴_as_first_letter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mot  Prononciation  H_aspiré           Type Audio  Pré_valide  \\\n",
       "1503702      ’tit             ti     False       adjectif    []        True   \n",
       "1503703  ’upa’upa      u.pa.u.pa     False            nom    []        True   \n",
       "1503704         €           ø.ʁo     False        symbole    []       False   \n",
       "1503705         ℁  o bɔ̃ swɛ̃ də     False    préposition    []       False   \n",
       "1503706         ∴      mɔʁ‿o.vaʃ     False  symbole_num=2    []       False   \n",
       "\n",
       "              Warn_code         Warn_label  \n",
       "1503702               -                  -  \n",
       "1503703               -                  -  \n",
       "1503704  err_lower_case  €_as_first_letter  \n",
       "1503705  err_lower_case  ℁_as_first_letter  \n",
       "1503706  err_lower_case  ∴_as_first_letter  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PmidCDRIAwl"
   },
   "outputs": [],
   "source": [
    "# corriger les & mal-formatés s'il y a en\n",
    "df['Mot'] = df['Mot'].str.replace('&amp;', '&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XIBkXvacY5sH",
    "outputId": "4c4b2df2-7a5a-4fc7-d528-7a2fc982de78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1503707"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage du nombre d'échantillons en entrées\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "COxsRMd09a1s"
   },
   "outputs": [],
   "source": [
    "df['Plausible'] = '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "fGy2OiKXEkQm",
    "outputId": "d5299641-eec8-4f01-df56-a86be98911eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audio</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>671929</td>\n",
       "      <td>gueulé</td>\n",
       "      <td>ɡœ.le</td>\n",
       "      <td>False</td>\n",
       "      <td>verbe_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1488734</td>\n",
       "      <td>épiglottalisaient</td>\n",
       "      <td>e.pi.ɡlɔ.ta.li.zɛ</td>\n",
       "      <td>False</td>\n",
       "      <td>verbe_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495582</td>\n",
       "      <td>désassommés</td>\n",
       "      <td>de.za.sɔ.me</td>\n",
       "      <td>False</td>\n",
       "      <td>verbe_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>842174</td>\n",
       "      <td>non-professionnel</td>\n",
       "      <td>nɔ̃.pʁɔ.fɛ.sjɔ.nɛl</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313668</td>\n",
       "      <td>commodisez</td>\n",
       "      <td>kɔ.mɔ.di.ze</td>\n",
       "      <td>False</td>\n",
       "      <td>verbe_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Mot       Prononciation  H_aspiré           Type Audio  \\\n",
       "671929              gueulé               ɡœ.le     False  verbe_flexion    []   \n",
       "1488734  épiglottalisaient   e.pi.ɡlɔ.ta.li.zɛ     False  verbe_flexion    []   \n",
       "495582         désassommés         de.za.sɔ.me     False  verbe_flexion    []   \n",
       "842174   non-professionnel  nɔ̃.pʁɔ.fɛ.sjɔ.nɛl     False            nom    []   \n",
       "313668          commodisez         kɔ.mɔ.di.ze     False  verbe_flexion    []   \n",
       "\n",
       "         Pré_valide Warn_code Warn_label Plausible  \n",
       "671929         True         -          -         ?  \n",
       "1488734        True         -          -         ?  \n",
       "495582         True         -          -         ?  \n",
       "842174         True         -          -         ?  \n",
       "313668         True         -          -         ?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage de 5 derniers échantillons\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "su8M2cf-AGNl",
    "outputId": "9b4be442-25bf-4745-e68e-4b23b8bca0c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audio</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1267690</td>\n",
       "      <td>résumpte</td>\n",
       "      <td>ʁe.zɔ̃pt</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1267691</td>\n",
       "      <td>résumpte</td>\n",
       "      <td>ʁe.zɔ̃t</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mot Prononciation  H_aspiré Type Audio  Pré_valide Warn_code  \\\n",
       "1267690  résumpte      ʁe.zɔ̃pt     False  nom    []        True         -   \n",
       "1267691  résumpte       ʁe.zɔ̃t     False  nom    []        True         -   \n",
       "\n",
       "        Warn_label Plausible  \n",
       "1267690          -         ?  \n",
       "1267691          -         ?  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Mot=='résumpte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpcCm53fcXVl"
   },
   "source": [
    "## Table de correspondance entre sons et lettres\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def read_table_de_correspondance():\n",
    "    df = pd.read_csv(\"table_de_correspondances.csv\")\n",
    "    phonemes2graphemes = {}\n",
    "    for phoneme in df.Phonème.values:\n",
    "        for position in df[df.Phonème == phoneme].Position.values:\n",
    "            for grapheme in df[df.Phonème == phoneme][df.Position == position].Graphème.values:\n",
    "                if phoneme not in phonemes2graphemes.keys():\n",
    "                    phonemes2graphemes[phoneme] = {}\n",
    "                phonemes2graphemes[phoneme][grapheme] = {}\n",
    "            \n",
    "    return phonemes2graphemes\n",
    "\n",
    "phonemes2graphemes = read_table_de_correspondance()\n",
    "\n",
    "def add_keys(phonemes2graphemes):\n",
    "  '''Ajoute des clés ('occurences', 'exemple_1', 'exemple_2', 'exemple_3')\n",
    "   dans le dictionnaire de chaque grapheme de la table phonemes2graphemes.'''\n",
    "\n",
    "  for phoneme in phonemes2graphemes.keys():\n",
    "    #for position in phonemes2graphemes[phoneme].keys():\n",
    "      for grapheme in phonemes2graphemes[phoneme].keys():\n",
    "        phonemes2graphemes[phoneme][grapheme]['occurences'] = 0\n",
    "        phonemes2graphemes[phoneme][grapheme]['exemple_1'] = ''\n",
    "        phonemes2graphemes[phoneme][grapheme]['exemple_2'] = ''\n",
    "        phonemes2graphemes[phoneme][grapheme]['exemple_3'] = ''\n",
    "\n",
    "  return phonemes2graphemes\n",
    "\n",
    "# run add_keys\n",
    "phonemes2graphemes = add_keys(phonemes2graphemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsDUfNANiXDs"
   },
   "source": [
    "## Fonctions de comptage pour statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-r1cTpGHmAso"
   },
   "outputs": [],
   "source": [
    "# fonction de comptage qui incrémente d'une unité le compteur de correspondance\n",
    "# entre un phonème donné et un graphème donné et qui enregistre en exemple \n",
    "# les trois premiers mots dans lequels la correspondance a été trouvé \n",
    "def increment_occurences(phoneme, grapheme, mot, unit_test=False):\n",
    "  \n",
    "  global phonemes2graphemes\n",
    "\n",
    "  # ne pas continuer si l'appel provient d'un test unitaire\n",
    "  if unit_test:\n",
    "    return\n",
    "\n",
    "  phonemes2graphemes[phoneme][grapheme]['occurences']  += 1\n",
    "  if phonemes2graphemes[phoneme][grapheme]['exemple_1']  == '':\n",
    "    phonemes2graphemes[phoneme][grapheme]['exemple_1'] = mot\n",
    "  elif phonemes2graphemes[phoneme][grapheme]['exemple_2']  == '':\n",
    "    phonemes2graphemes[phoneme][grapheme]['exemple_2'] = mot\n",
    "  elif phonemes2graphemes[phoneme][grapheme]['exemple_3']  == '':\n",
    "    phonemes2graphemes[phoneme][grapheme]['exemple_3'] = mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "nNXz97yImhDC",
    "outputId": "8ad76acb-a3d3-4526-b185-a14aa62197e4"
   },
   "outputs": [],
   "source": [
    "# fonction de statistiques qui calcule pour pour chaque position (initiale,\n",
    "# intermédiaire ou finale) le nombre d'occurences de chaque graphème ainsi\n",
    "# que la probabilité de ce graphème.\n",
    "# Les résultats sont insérés dans un DataFrame pandas et dans un fichier CSV.\n",
    "\n",
    "def make_stats():\n",
    "  global phonemes2graphemes\n",
    "\n",
    "  table = []\n",
    "  for phoneme in phonemes2graphemes:\n",
    "      for grapheme in phonemes2graphemes[phoneme].keys():\n",
    "        occurences = phonemes2graphemes[phoneme][grapheme]['occurences']\n",
    "        exemple_1 = phonemes2graphemes[phoneme][grapheme]['exemple_1']\n",
    "        exemple_2 = phonemes2graphemes[phoneme][grapheme]['exemple_2']\n",
    "        exemple_3 = phonemes2graphemes[phoneme][grapheme]['exemple_3']\n",
    "\n",
    "        #print(\"phoneme=%s grapheme=%s occurences=%d\" % (phoneme, grapheme, occurences))\n",
    "        row = { 'phonème': phoneme, 'graphème':grapheme, 'occurences':occurences, 'pourcentage':0.0,\n",
    "               'exemple_1' : exemple_1, 'exemple_2' : exemple_2, 'exemple_3' : exemple_3, }\n",
    "        table.append(row)\n",
    "  dfp = pd.DataFrame.from_dict(table)\n",
    "\n",
    "  for phoneme in dfp['phonème'].unique():\n",
    "      df1 = dfp[dfp['phonème'] == phoneme]\n",
    "\n",
    "      # calculate the sum of used graphemes within each phoneme-position category\n",
    "      sum = 0\n",
    "      for grapheme in df1['graphème'].unique():\n",
    "        row_number = df1.loc[df1.graphème==grapheme].index[0]\n",
    "        occurences = df1.at[row_number, 'occurences']\n",
    "        sum += occurences\n",
    "\n",
    "      # set the pourcentage of each graphemes for each phoneme-position category\n",
    "      if sum != 0:\n",
    "        for grapheme in df1['graphème'].unique():\n",
    "          row_number = df1.loc[df1.graphème==grapheme].index[0]\n",
    "          occurences = df1.at[row_number, 'occurences']\n",
    "          pourcentage = int(occurences/sum*100)/100\n",
    "          dfp.at[row_number, 'pourcentage'] = pourcentage\n",
    "\n",
    "      dfp.to_csv(\"phonemes2graphemes.csv\", index=False)\n",
    "\n",
    "  return dfp\n",
    "\n",
    "_ = make_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1v0fIw3nuU8"
   },
   "source": [
    "## Fonction de test de plausibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeQZ2cWYoCQG"
   },
   "outputs": [],
   "source": [
    "# Fonction récursive tentant de retrouver tout ou partie des graphemes\n",
    "# depuis tout ou partie des phonemes, à l'aide de la table de correspondance\n",
    "# entre les phonemes et les graphemes.\n",
    "\n",
    "def process_graphemes(mot, phonemes, graphemes, \n",
    "                      phoneme_index=0, grapheme_index=0, \n",
    "                      phonemes_hist='', graphemes_hist='', \n",
    "                      unit_test = False, verbose=False,):\n",
    "  \n",
    "  if verbose:\n",
    "    print('')\n",
    "    print('process_graphemes(phonemes=\\\\%s\\\\, graphemes=[[%s]], \\\n",
    "    phoneme_index=%d, grapheme_index=%d, \\\n",
    "    phonemes_hist=%s, graphemes_hist=%s)' \n",
    "            % (phonemes, graphemes, phoneme_index, grapheme_index, phonemes_hist, graphemes_hist))\n",
    "\n",
    "  global phonemes2graphemes\n",
    "\n",
    "  if grapheme_index >= len(graphemes):\n",
    "    if ''.join(graphemes_hist) == graphemes and ''.join(phonemes_hist)==phonemes:\n",
    "        if verbose:\n",
    "            print('ended ok')            \n",
    "        return True, phonemes_hist.copy(), graphemes_hist.copy()\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('ended ko')\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "\n",
    "  current_candidate_phonemes = []\n",
    "  for phoneme in phonemes2graphemes:    \n",
    "    if phonemes[phoneme_index:].startswith(phoneme):      \n",
    "      current_candidate_phonemes.append(phoneme)\n",
    "  if len(current_candidate_phonemes) == 0:\n",
    "    return False, phonemes_hist, graphemes_hist\n",
    "  if verbose:\n",
    "    if len(current_candidate_phonemes) > 1:\n",
    "      print(\"### candidate current phonemes=%\", current_candidate_phonemes)\n",
    "\n",
    "  nb_current_candidate_phonemes = 0 \n",
    "\n",
    "  for current_phoneme in current_candidate_phonemes:\n",
    "    if verbose:\n",
    "      print(\"trying candidate current phoneme=%s\" % current_phoneme)\n",
    "    nb_current_candidate_phonemes += 1\n",
    "    next_phoneme = ''\n",
    "\n",
    "    last_graphemes = graphemes[grapheme_index:]\n",
    "    \n",
    "    if verbose:\n",
    "      print('process_graphemes(phonemes=\\\\%s\\\\, graphemes=[[%s]], phoneme_index=%d, grapheme_index=%d) current_phoneme:%s' \n",
    "            % (phonemes, graphemes, phoneme_index, grapheme_index, current_phoneme))\n",
    "  \n",
    "    if verbose:\n",
    "      print('current_phoneme:%s' % current_phoneme)\n",
    "    \n",
    "    try:\n",
    "      len(phonemes2graphemes[current_phoneme])\n",
    "    except:\n",
    "      a=1\n",
    "      if current_phoneme == '':\n",
    "        if verbose:\n",
    "          print('wrn: in [[%s]] : phoneme \\\\%s\\\\ does not exist !!!' % (graphemes, current_phoneme))\n",
    "        return True, phonemes_hist, graphemes_hist\n",
    "      else:\n",
    "        print('err: in [[%s]] : phoneme \\\\%s\\\\ does not exist !!!' % (graphemes, current_phoneme))\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "\n",
    "    matching_graphemes_list = []\n",
    "\n",
    "    for current_graphemes in phonemes2graphemes[current_phoneme]:\n",
    "    \n",
    "      if last_graphemes.startswith(current_graphemes):\n",
    "        if verbose:\n",
    "          print('phoneme \\\\%s\\\\ matching graphemes [[%s]] (last_graphemes:[[%s]])' % (current_phoneme, current_graphemes, last_graphemes))\n",
    "        matching_graphemes_list.append(current_graphemes)\n",
    "\n",
    "    if len(matching_graphemes_list) == 0:\n",
    "      if verbose:\n",
    "        print('KO0: phonemes=\\\\%s\\\\ does not match any grapheme !!!' % (phonemes))\n",
    "\n",
    "      if nb_current_candidate_phonemes == len(current_candidate_phonemes):\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "      else:\n",
    "        if verbose:\n",
    "          print('move0 to next candidate phoneme')\n",
    "        continue\n",
    "      \n",
    "    #print('current_phoneme=', current_phoneme)\n",
    "    \n",
    "    ### * ###\n",
    "    if len(matching_graphemes_list) == 0:\n",
    "        if verbose:\n",
    "          print('KO: phoneme \\\\%s\\\\ matches NO grapheme (in word [[%s]])  !!!' % (graphemes, phonemes))\n",
    "        phonemes_hist.pop()\n",
    "        graphemes_hist.pop()\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "\n",
    "    for current_graphemes in matching_graphemes_list:\n",
    "        \n",
    "        phonemes_hist.append(current_phoneme)\n",
    "        graphemes_hist.append(current_graphemes)\n",
    "\n",
    "        if verbose:\n",
    "          print(\"trying2 current_phoneme \\\\%s\\\\ and current_graphemes [[%s]]\" % (current_phoneme, current_graphemes))\n",
    "\n",
    "        ret, phonemes_hist2, graphemes_hist2 = process_graphemes(\n",
    "            mot,\n",
    "            phonemes, \n",
    "            graphemes,\n",
    "            phoneme_index=phoneme_index+len(current_phoneme), \n",
    "            grapheme_index=grapheme_index+len(current_graphemes),\n",
    "            phonemes_hist = phonemes_hist,\n",
    "            graphemes_hist = graphemes_hist,\n",
    "            unit_test = unit_test,\n",
    "            verbose=verbose)           \n",
    "                \n",
    "        # si la concatenation des graphemes trouvées jusqu'ici n'est pas bonne, alors pas bon\n",
    "        if not graphemes.startswith(''.join(graphemes_hist)):\n",
    "            if verbose:\n",
    "                print(''.join(graphemes_hist)+current_graphemes)\n",
    "                print(graphemes)\n",
    "                print('current_graphemes does not match previous findings')\n",
    "            ret = False          \n",
    "                \n",
    "          # si la concatenation des graphemes trouvées jusqu'ici n'est pas bonne, alors pas bon\n",
    "\n",
    "      \n",
    "        if ret == True:\n",
    "          if verbose:\n",
    "            print('phonemes_hist2b:', phonemes_hist2)\n",
    "            print('graphemes_hist2b:', graphemes_hist2)\n",
    "            print(\"current_phoneme \\\\%s\\\\ and current_graphemes [[%s]] : worked ok\" % (current_phoneme, current_graphemes))\n",
    "          \n",
    "          increment_occurences(current_phoneme, current_graphemes, mot, unit_test)\n",
    "          return True, phonemes_hist2, graphemes_hist2\n",
    "    \n",
    "        phonemes_hist.pop()\n",
    "        graphemes_hist.pop()\n",
    "      \n",
    "    # if here LOST\n",
    "    if verbose:\n",
    "          print('LOST2 for current_phoneme \\\\%s\\\\ in process_graphemes(phonemes=\\\\%s\\\\, graphemes=[[%s]], phoneme_index=%d, grapheme_index=%d)' \n",
    "                % (current_phoneme, phonemes, graphemes, phoneme_index, grapheme_index))\n",
    "    \n",
    "    if nb_current_candidate_phonemes == len(current_candidate_phonemes):\n",
    "        return False, phonemes_hist2, graphemes_hist2\n",
    "    else:\n",
    "       \n",
    "        if verbose:\n",
    "          print('move2 to next candidate phoneme')\n",
    "        continue\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ZlfYwF1opiA"
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOS9qKRWzO42"
   },
   "source": [
    "### Exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhYXjOSbo9_I"
   },
   "outputs": [],
   "source": [
    "exemples = [\n",
    "    (\"momie\", \"mɔmi\"),\n",
    "    (\"pookie\", \"puki\"),\n",
    "\n",
    "]\n",
    "\n",
    "for exemple in exemples:\n",
    "    \n",
    "    mot = exemple[0]\n",
    "    graphemes = exemple[0]\n",
    "    phonemes = exemple[1]\n",
    "    \n",
    "    res = process_graphemes(mot, phonemes, graphemes, \n",
    "                            phoneme_index=0, grapheme_index=0, \n",
    "                            phonemes_hist=[], graphemes_hist=[],\n",
    "                            unit_test=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uh0wZe67re4Z"
   },
   "outputs": [],
   "source": [
    "def check_word_pronunciation(mot, phonemes, graphemes, unit_test=False, verbose0=False, verbose1=False, verbose2=False):\n",
    "\n",
    "    res, phonemes2, graphemes2  = process_graphemes(mot, phonemes, graphemes, phoneme_index=0, grapheme_index=0, phonemes_hist=[], graphemes_hist=[], unit_test=unit_test, verbose=verbose2)\n",
    "    prononciation = ''.join(phonemes2)\n",
    "    word = ''.join(graphemes2)\n",
    "    prononciation_ = ','.join(phonemes2)\n",
    "    word_ = ','.join(graphemes2)\n",
    "    if prononciation != phonemes:\n",
    "      if verbose0:\n",
    "        print('[[%s]] \\\\%s\\\\ -> prononciation=\\\\%s\\\\ ' % (mot, phonemes, prononciation ))\n",
    "      return False\n",
    "    elif word != graphemes.replace('-','').replace(' ',''):\n",
    "      if verbose0:\n",
    "        print('[[%s]] != output graphemes=%s' % (mot, word))\n",
    "      return True\n",
    "    else:\n",
    "      if verbose0:\n",
    "        print('%s \\\\%s\\\\ -> %s \\\\%s\\\\' % (mot, prononciation, word_, prononciation_))\n",
    "      return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXWXcxH2xf-A"
   },
   "source": [
    "### Tests de référence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "4CZD_l1chhQO",
    "outputId": "6b3a727a-dd48-46fc-ff70-7b99fe30cb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acéphalobrache \\asefalɔbʁak\\ -> a,c,é,ph,a,l,o,b,r,a,che \\a,s,e,f,a,l,ɔ,b,ʁ,a,k\\\n",
      "acquaintance \\akwɛ̃tɑ̃s\\ -> a,cq,u,ain,t,an,ce \\a,k,w,ɛ̃,t,ɑ̃,s\\\n",
      "agoua \\aɡwa\\ -> a,g,ou,a \\a,ɡ,w,a\\\n",
      "bêchâmes \\beʃam\\ -> b,ê,ch,â,mes \\b,e,ʃ,a,m\\\n",
      "caouanne \\kawan\\ -> c,a,ou,a,nne \\k,a,w,a,n\\\n",
      "designer \\dizajnœʁ\\ -> d,e,s,i,g,n,e,r \\d,i,z,a,j,n,œ,ʁ\\\n",
      "désembouteillions \\dezɑ̃butɛjɔ̃\\ -> d,é,s,em,b,ou,t,e,illi,ons \\d,e,z,ɑ̃,b,u,t,ɛ,j,ɔ̃\\\n",
      "disjonctés \\diʒɔ̃kte\\ -> d,is,j,on,c,t,és \\d,i,ʒ,ɔ̃,k,t,e\\\n",
      "droitismes \\dʁwatism\\ -> d,r,o,i,t,i,s,mes \\d,ʁ,w,a,t,i,s,m\\\n",
      "élégante \\eleɡɑ̃t\\ -> é,l,é,g,an,te \\e,l,e,ɡ,ɑ̃,t\\\n",
      "enarrhas \\ɑ̃naʁa\\ -> e,n,a,rrh,as \\ɑ̃,n,a,ʁ,a\\\n",
      "enfutailler \\ɑ̃fytɑje\\ -> en,f,u,t,a,ill,er \\ɑ̃,f,y,t,ɑ,j,e\\\n",
      "excaverai \\ɛkskavəʁe\\ -> e,x,c,a,v,e,r,ai \\ɛ,ks,k,a,v,ə,ʁ,e\\\n",
      "exemple \\ɛɡzɑ̃pl\\ -> e,x,em,p,le \\ɛ,ɡz,ɑ̃,p,l\\\n",
      "fashion \\faʃœn\\ -> f,a,sh,io,n \\f,a,ʃ,œ,n\\\n",
      "khartoumisé \\kaʁtumize\\ -> k,ha,r,t,ou,m,i,s,é \\k,a,ʁ,t,u,m,i,z,e\\\n",
      "hauts \\o\\ -> hauts \\o\\\n",
      "hauts-fonds \\ofɔ̃\\ -> hauts,f,onds \\o,f,ɔ̃\\\n",
      "html \\aʃteɛmɛl\\ -> h,t,m,l \\aʃ,te,ɛm,ɛl\\\n",
      "intérêt \\ɛ̃teʁɛ\\ -> in,t,é,r,êt \\ɛ̃,t,e,ʁ,ɛ\\\n",
      "intéressant \\ɛ̃teʁɛsɑ̃\\ -> in,t,é,r,es,s,ant \\ɛ̃,t,e,ʁ,ɛ,s,ɑ̃\\\n",
      "jaïnas \\dʒaina\\ -> j,a,ï,n,as \\dʒ,a,i,n,a\\\n",
      "luxe \\lyks\\ -> l,u,xe \\l,y,ks\\\n",
      "momie \\mɔmi\\ -> m,o,m,ie \\m,ɔ,m,i\\\n",
      "oiseaux \\wazo\\ -> o,i,s,eaux \\w,a,z,o\\\n",
      "ondoyés \\ɔ̃dwaje\\ -> on,d,o,y,és \\ɔ̃,d,w,aj,e\\\n",
      "peopliser \\piplize\\ -> p,eo,p,l,i,s,er \\p,i,p,l,i,z,e\\\n",
      "pookie \\puki\\ -> p,oo,k,ie \\p,u,k,i\\\n",
      "rechaterais \\ʁətʃatəʁɛ\\ -> r,e,c,h,a,t,e,r,ais \\ʁ,ə,t,ʃ,a,t,ə,ʁ,ɛ\\\n",
      "solex \\solɛks\\ -> s,o,l,e,x \\s,o,l,ɛ,ks\\\n",
      "Paris \\paʁi\\ -> p,a,r,is \\p,a,ʁ,i\\\n",
      "VPN \\vepeɛn\\ -> v,p,n \\ve,pe,ɛn\\\n"
     ]
    }
   ],
   "source": [
    "essais = [\n",
    "    (\"acéphalobrache\", \"asefalɔbʁak\"),\n",
    "    (\"acquaintance\",\"akwɛ̃tɑ̃s\"),\n",
    "    (\"agoua\",\"aɡwa\"),\n",
    "    (\"bêchâmes\",\"beʃam\"),\n",
    "    (\"caouanne\",\"kawan\"),\n",
    "    (\"designer\",\"dizajnœʁ\"),\n",
    "    (\"désembouteillions\",\"dezɑ̃butɛjɔ̃\"),\n",
    "    (\"disjonctés\",\"diʒɔ̃kte\"),\n",
    "    (\"droitismes\", \"dʁwatism\"),\n",
    "    (\"élégante\", \"eleɡɑ̃t\"),\n",
    "    (\"enarrhas\", \"ɑ̃naʁa\"),\n",
    "    (\"enfutailler\", \"ɑ̃fytɑje\"),\n",
    "    (\"excaverai\", \"ɛkskavəʁe\"),\n",
    "    (\"exemple\", \"ɛɡzɑ̃pl\"),\n",
    "    (\"fashion\",\"faʃœn\"),\n",
    "    (\"khartoumisé\",\"kaʁtumize\"),\n",
    "    (\"hauts\", \"o\"),\n",
    "    ('hauts-fonds','o.fɔ̃'),\n",
    "    (\"html\", \"aʃteɛmɛl\"), #acronyme\n",
    "    (\"intérêt\", \"ɛ̃teʁɛ\"),\n",
    "    (\"intéressant\",\"ɛ̃teʁɛsɑ̃\"),\n",
    "    (\"jaïnas\",\"dʒaina\"),\n",
    "    (\"luxe\",\"lyks\"),\n",
    "    (\"momie\",\"mɔmi\"),\n",
    "    (\"oiseaux\", \"wazo\"),\n",
    "    (\"ondoyés\", \"ɔ̃dwaje\"),\n",
    "    (\"peopliser\",\"piplize\"),\n",
    "    (\"pookie\", \"puki\"),\n",
    "    (\"rechaterais\", \"ʁətʃatəʁɛ\"),\n",
    "    ('solex', 'solɛks'),\n",
    "    ('Paris', 'pa.ʁi'),\n",
    "    ('VPN', 've.pe.ɛn'),\n",
    "    \n",
    "]\n",
    "\n",
    "for essai in essais:\n",
    "  #check_word_pronunciation(essai[0], essai[1].replace('.',''), essai[0].lower().replace('-',''), unit_test=True, verbose0=True, verbose1=False, verbose2=False)\n",
    "  check_word_pronunciation(essai[0], essai[1].replace('.',''), essai[0].lower().replace('-',''), unit_test=True, verbose0=True, verbose1=False, verbose2=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_E7sUaT5bd2U"
   },
   "source": [
    "### Test en masse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1aSsYCmh3J0R",
    "outputId": "61692a02-e47c-498f-e447-dcc83f2d84fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503707, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "pWuUXTC23K8P",
    "outputId": "6aba893e-bae7-41a9-a89d-8637e495fc60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb mots composés:160936\n",
      "nb mots préfixes:425\n",
      "nb mots noms communs:1310205\n",
      "nb mots noms propres:29043\n",
      "nb mots sigles:1996\n",
      "nb mots autres:1102\n",
      "nb mots TOTAL:1505703\n"
     ]
    }
   ],
   "source": [
    "# trier le dataframe (noms communs, acronymes, noms propres, puis restants)\n",
    "# pour des exemples plus significatifs dans les statistiques\n",
    "df_composés = df[df.Mot.str.match('..*?[\\-\\ ].*?.')].copy()\n",
    "print(\"nb mots composés:%d\" % df_composés.shape[0])\n",
    "\n",
    "df_autres_0 = pd.concat([df, df_composés, df_composés]).drop_duplicates(keep=False)\n",
    "df_préfixes = df_autres_0[df_autres_0.Mot.str.startswith('-')].copy()\n",
    "print(\"nb mots préfixes:%d\" % df_préfixes.shape[0])\n",
    "\n",
    "df_autres_1 = pd.concat([df_autres_0, df_préfixes, df_préfixes]).drop_duplicates(keep=False)\n",
    "df_nc = df_autres_1[df_autres_1.Mot.str.islower()].copy()\n",
    "print(\"nb mots noms communs:%d\" % df_nc.shape[0])\n",
    "\n",
    "df_autres_2 = pd.concat([df_autres_1, df_nc, df_nc]).drop_duplicates(keep=False)\n",
    "df_np = df_autres_2[df_autres_2.Mot.str.istitle()].copy()\n",
    "print(\"nb mots noms propres:%d\" % df_np.shape[0])\n",
    "\n",
    "df_autres_3 = pd.concat([df_autres_2, df_np, df_np]).drop_duplicates(keep=False)\n",
    "df_sigles = df_autres_3[df_autres_3.Mot.str.isupper()].copy()\n",
    "print(\"nb mots sigles:%d\" % df_sigles.shape[0])\n",
    "\n",
    "df_autres_4 = pd.concat([df_autres_3, df_sigles, df_sigles]).drop_duplicates(keep=False)\n",
    "print(\"nb mots autres:%d\" % df_autres_4.shape[0])\n",
    "\n",
    "# mettre dans un ordre augmentant les probabilités de succès des noms composés\n",
    "df_new = pd.concat([df_nc, df_sigles, df_np, df_composés, df_préfixes, df_sigles, df_autres_4], ignore_index=True).copy()\n",
    "print(\"nb mots TOTAL:%d\" % df_new.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "aQ_ek99vrt_y",
    "outputId": "0ec71f7e-8912-4d98-9193-bacf6891c823"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audio</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1452434</td>\n",
       "      <td>xDSL</td>\n",
       "      <td>iks.de.ɛs‿ɛl</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>['LL-Q150 (fra)-Ltrlg-xDSL.wav']</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1461769</td>\n",
       "      <td>éSwatini</td>\n",
       "      <td>e.swa.ti.ni</td>\n",
       "      <td>False</td>\n",
       "      <td>nom propre</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1503704</td>\n",
       "      <td>€</td>\n",
       "      <td>ø.ʁo</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>€_as_first_letter</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1503705</td>\n",
       "      <td>℁</td>\n",
       "      <td>o bɔ̃ swɛ̃ də</td>\n",
       "      <td>False</td>\n",
       "      <td>préposition</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>℁_as_first_letter</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1503706</td>\n",
       "      <td>∴</td>\n",
       "      <td>mɔʁ‿o.vaʃ</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole_num=2</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>∴_as_first_letter</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mot  Prononciation  H_aspiré           Type  \\\n",
       "1452434      xDSL   iks.de.ɛs‿ɛl     False            nom   \n",
       "1461769  éSwatini    e.swa.ti.ni     False     nom propre   \n",
       "1503704         €           ø.ʁo     False        symbole   \n",
       "1503705         ℁  o bɔ̃ swɛ̃ də     False    préposition   \n",
       "1503706         ∴      mɔʁ‿o.vaʃ     False  symbole_num=2   \n",
       "\n",
       "                                    Audio  Pré_valide       Warn_code  \\\n",
       "1452434  ['LL-Q150 (fra)-Ltrlg-xDSL.wav']        True               -   \n",
       "1461769                                []        True               -   \n",
       "1503704                                []       False  err_lower_case   \n",
       "1503705                                []       False  err_lower_case   \n",
       "1503706                                []       False  err_lower_case   \n",
       "\n",
       "                Warn_label Plausible  \n",
       "1452434                  -         ?  \n",
       "1461769                  -         ?  \n",
       "1503704  €_as_first_letter         ?  \n",
       "1503705  ℁_as_first_letter         ?  \n",
       "1503706  ∴_as_first_letter         ?  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_autres_4.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "01jCIjPAhhQp",
    "outputId": "e21472f2-c2e4-443a-e4fc-4e5b78ac271a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1505048, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df_new\n",
    "#df2=df2[df2.Mot.str.istitle()] # ne conserver que les mots commençant par une majuscule puis minuscules\n",
    "#df2=df2[df2.Mot.str.islower()] # ne conserver que les mots entièrement en minuscules (i.e. noms communs)\n",
    "#df2=df2[df2.Mot.str.isupper()] # ne conserver que les mots entièrement en majuscules (i.e. acronymes)#\n",
    "#df2=df2[df2.Mot.str.startswith('x')] # ne conserver que les mots noms communs commençant par ...\n",
    "#df2 = pd.concat([df2, df_composés, df_composés]).drop_duplicates(keep=False) # supprimer les mots composés\n",
    "#df2 = df2[~df2.Mot.str.contains(' ')] # exclure les mots contenant un espace\n",
    "#df2 = df2[~df2.Mot.str.contains('-')] # exclure les mots contenant un tiret\n",
    "\n",
    "df2 = df2[~df2.Mot.str.contains('\\.')] # exclure les mots contenant un point\n",
    "df2 = df2[~df2.Mot.str.contains('/')] # exclure les mots contenant un slash (e.g. copier/coller)\n",
    "\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "JOCz6EX3hhQ0",
    "outputId": "2ef3b62b-3112-4ceb-b3c4-49e0e8cb8892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:1, nb_samples:150504, durée:0:00:42.236872\n",
      "batch:2, nb_samples:301008, durée:0:00:41.526414\n",
      "batch:3, nb_samples:451512, durée:0:00:44.667519\n",
      "batch:4, nb_samples:602016, durée:0:00:41.841617\n",
      "batch:5, nb_samples:752520, durée:0:00:41.774246\n",
      "batch:6, nb_samples:903024, durée:0:00:43.574572\n",
      "batch:7, nb_samples:1053528, durée:0:00:43.527668\n",
      "batch:8, nb_samples:1204032, durée:0:00:43.467068\n",
      "batch:9, nb_samples:1354536, durée:0:01:45.629874\n",
      "batch:10, nb_samples:1505040, durée:0:04:12.100342\n",
      "nb_samples: 1505048  durée de processing du dernier batch: 0:00:00.001888\n",
      "samples=1505048, samples_ok=1497769, samples_ko=7279, very_bad=0, ok%=99.52\n"
     ]
    }
   ],
   "source": [
    "nb_samples=0\n",
    "nb_infos_steps=10\n",
    "nb_samples_steps = int(df2.shape[0]/nb_infos_steps)\n",
    "nb_samples_ok=0\n",
    "nb_samples_ko=0\n",
    "nb_very_bad=0\n",
    "nb_batch=0\n",
    "verbose=False\n",
    "indexes_to_forget = []\n",
    "nb_composés = 0\n",
    "nb_composés_directs_found = 0\n",
    "nb_composés_indirects_found = 0\n",
    "\n",
    "t0 = datetime.datetime.now()\n",
    "for index, row in df2.iterrows():\n",
    "\n",
    "    nb_samples += 1\n",
    "    is_ok = False\n",
    "    is_skipped = False\n",
    "        \n",
    "    if nb_samples >= nb_infos_steps and nb_samples % nb_samples_steps == 0:\n",
    "      nb_batch += 1\n",
    "      t1 = datetime.datetime.now()\n",
    "      durée = t1 - t0\n",
    "      print('batch:%d, nb_samples:%d, durée:%s' % (nb_batch, nb_samples, durée))\n",
    "      t0 = t1\n",
    "\n",
    "    mot = row['Mot']\n",
    "    prononciation = row['Prononciation']\n",
    " \n",
    "    is_composé = False\n",
    "    is_composé_direct = False\n",
    "    if ' ' in row['Mot'] or ',' in row['Mot'] or '-' in row['Mot']:\n",
    "      nb_composés += 1     \n",
    "      is_composé = True\n",
    "        \n",
    "    try:\n",
    "      graphemes = row['Mot'].lower().replace(' ', '').replace('-','').replace(',','')\n",
    "      phonemes = prononciation.replace('(','').replace(')','').replace('‿','').replace('.','').replace(' ','')\n",
    "      is_ok = check_word_pronunciation(mot, phonemes, graphemes, False, False, False, False)\n",
    "          \n",
    "      if is_ok:\n",
    "        if ' ' in row['Mot'] or ',' in row['Mot'] or '-' in row['Mot']:\n",
    "          is_composé_direct = True\n",
    "          nb_composés_directs_found += 1      \n",
    "    \n",
    "    except:\n",
    "      is_ok = False\n",
    "      is_skipped = True \n",
    "      nb_very_bad+=1\n",
    "      # mauvaise lettre ou phoneme, pas la peine d'aller plus loi\n",
    "      # passer au mot suivant\n",
    "\n",
    "    # si la correspondance n'a pas été trouvé, tester si le mot est composé,\n",
    "    # et si oui, tester la correspondance de chaque partie (aka sous-mot)\n",
    "    if not is_ok and not is_skipped:    \n",
    "      graphemes = row['Mot'].lower().replace(',','')\n",
    "      phonemes = prononciation    \n",
    "      separateurs = [' ', '-']\n",
    "      for separateur in separateurs:\n",
    "        if separateur in graphemes[1:-1] :\n",
    "          mots_ = mot.split(separateur)\n",
    "          # si le mot n'est pas un mot composé, l'oubler, et passer à la suite\n",
    "          if len(mots_) <= 1:\n",
    "            continue\n",
    "          for mot_ in mots_:\n",
    "            try:\n",
    "              # récuperer le sous-mot identifiés ainsi que ses différentes prononciations possibles\n",
    "              phonemess_ = df[df.Mot==mot_]['Prononciation'].values\n",
    "              for phonemes_ in phonemess_:\n",
    "                graphemes_ = mot_\n",
    "                phonemes_ = phonemes_.replace('(','').replace(')','').replace('‿','').replace('.','').replace(' ','')\n",
    "                is_ok_ = check_word_pronunciation(mot_, phonemes_, graphemes_, False, False, False, False)\n",
    "                if is_ok_:\n",
    "                    break                    \n",
    "              if is_ok_ == False:\n",
    "                is_ok = False                \n",
    "              else:\n",
    "                is_ok = True\n",
    "                break\n",
    "            except:\n",
    "              is_ok = False\n",
    "            \n",
    "    if is_ok and is_composé:\n",
    "        if not is_composé_direct:\n",
    "            nb_composés_indirects_found += 1\n",
    "    #if not is_ok and is_composé:\n",
    "    #    print('word=%s \\\\\\\\%s\\\\\\\\'% (mot, prononciation))\n",
    "        \n",
    "    if is_ok:\n",
    "      nb_samples_ok += 1\n",
    "      df2.at[index, 'Plausible']='oui'\n",
    "      indexes_to_forget.append(index)\n",
    "    else:\n",
    "      nb_samples_ko += 1\n",
    "      if verbose:\n",
    "        if row['Type'] != 'verbe_flexion':\n",
    "          print('word=%s \\\\\\\\%s\\\\\\\\'% (mot, prononciation))\n",
    "      df2.at[index, 'Plausible']='non'\n",
    "        \n",
    "\n",
    "t1 = datetime.datetime.now()\n",
    "durée = t1 - t0\n",
    "print('nb_samples:', nb_samples, ' durée de processing du dernier batch:', durée)\n",
    "      \n",
    "df2 = df2.drop(indexes_to_forget)\n",
    "\n",
    "if nb_samples > 0:\n",
    "  print('samples=%d, samples_ok=%d, samples_ko=%d, very_bad=%d, ok%%=%.2f' % \\\n",
    "        (nb_samples, nb_samples_ok, nb_samples_ko, nb_very_bad, \\\n",
    "         nb_samples_ok/nb_samples*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_samples: 1292602  durée de processing du dernier batch: 0:00:00.000838\n",
    "#samples=1292602, samples_ok=1279990, samples_ko=12612, very_bad=0 %ok=99.02\n",
    "\n",
    "#samples=1485362, samples_ok=1471019, samples_ko=14343, very_bad=0, ok%=99.03\n",
    "#nb_composés:160151\n",
    "#nb_composés_directs_found:154583\n",
    "#nb_composés_indirects_found:5216\n",
    "#nb_composés_not_found:352\n",
    "\n",
    "#samples=1485362, samples_ok=1468451, samples_ko=16911, very_bad=0, ok%=98.86\n",
    "#nb_composés:160151\n",
    "#nb_composés_directs_found:0\n",
    "#nb_composés_indirects_found:157231\n",
    "#nb_composés_not_found:2920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6X8pia-32RtQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7279"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nombre de mots dont la prononciation est détectée comme non plausible\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFgO0o3H4Srh",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audio</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1505521</td>\n",
       "      <td>Selk’nam</td>\n",
       "      <td>sɛlk.nam</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>S_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505523</td>\n",
       "      <td>TADs</td>\n",
       "      <td>te.a.de</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>T_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505609</td>\n",
       "      <td>URNs</td>\n",
       "      <td>y.ɛʁ.ɛn</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>U_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505610</td>\n",
       "      <td>UpM</td>\n",
       "      <td>y.pe.em</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>U_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505621</td>\n",
       "      <td>Vosg’patt</td>\n",
       "      <td>voʒ.pat</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[\"LL-Q150 (fra)-Penegal-Vosg'patt.wav\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>V_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505622</td>\n",
       "      <td>WEIs</td>\n",
       "      <td>ˈwaj ou ˈwɛj</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>W_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505623</td>\n",
       "      <td>Wuchiaping’ien</td>\n",
       "      <td>wu.tʃja.piŋ.jɛ̃</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>W_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505625</td>\n",
       "      <td>XPs</td>\n",
       "      <td>iks.pe</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>X_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505627</td>\n",
       "      <td>Xi’an</td>\n",
       "      <td>ʃi.an</td>\n",
       "      <td>False</td>\n",
       "      <td>nom propre</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>X_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505628</td>\n",
       "      <td>Xi’an</td>\n",
       "      <td>sjan</td>\n",
       "      <td>False</td>\n",
       "      <td>nom propre</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>X_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505631</td>\n",
       "      <td>YouTubeur</td>\n",
       "      <td>ju.tju.bœʁ</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>Y_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505633</td>\n",
       "      <td>YouTubeurs</td>\n",
       "      <td>ju.tju.bœʁ</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>Y_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505635</td>\n",
       "      <td>YouTubeuse</td>\n",
       "      <td>ju.tju.bøz</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>Y_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505637</td>\n",
       "      <td>YouTubeuses</td>\n",
       "      <td>ju.tju.bøz</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>Y_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505680</td>\n",
       "      <td>d’Ursel</td>\n",
       "      <td>dyʁs</td>\n",
       "      <td>False</td>\n",
       "      <td>nom de famille</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505692</td>\n",
       "      <td>microSD</td>\n",
       "      <td>s</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505696</td>\n",
       "      <td>raï'n'B</td>\n",
       "      <td>ʁaj.ɛn.bi</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_letters</td>\n",
       "      <td>'</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505700</td>\n",
       "      <td>€</td>\n",
       "      <td>ø.ʁo</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>€_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505701</td>\n",
       "      <td>℁</td>\n",
       "      <td>o bɔ̃ swɛ̃ də</td>\n",
       "      <td>False</td>\n",
       "      <td>préposition</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>℁_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505702</td>\n",
       "      <td>∴</td>\n",
       "      <td>mɔʁ‿o.vaʃ</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole_num=2</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>∴_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mot    Prononciation  H_aspiré            Type  \\\n",
       "1505521        Selk’nam         sɛlk.nam     False             nom   \n",
       "1505523            TADs          te.a.de     False     nom_flexion   \n",
       "1505609            URNs          y.ɛʁ.ɛn     False     nom_flexion   \n",
       "1505610             UpM          y.pe.em     False             nom   \n",
       "1505621       Vosg’patt          voʒ.pat     False             nom   \n",
       "1505622            WEIs     ˈwaj ou ˈwɛj     False     nom_flexion   \n",
       "1505623  Wuchiaping’ien  wu.tʃja.piŋ.jɛ̃     False             nom   \n",
       "1505625             XPs           iks.pe     False     nom_flexion   \n",
       "1505627           Xi’an            ʃi.an     False      nom propre   \n",
       "1505628           Xi’an             sjan     False      nom propre   \n",
       "1505631       YouTubeur       ju.tju.bœʁ     False             nom   \n",
       "1505633      YouTubeurs       ju.tju.bœʁ     False     nom_flexion   \n",
       "1505635      YouTubeuse       ju.tju.bøz     False     nom_flexion   \n",
       "1505637     YouTubeuses       ju.tju.bøz     False     nom_flexion   \n",
       "1505680         d’Ursel             dyʁs     False  nom de famille   \n",
       "1505692         microSD                s     False             nom   \n",
       "1505696         raï'n'B        ʁaj.ɛn.bi     False             nom   \n",
       "1505700               €             ø.ʁo     False         symbole   \n",
       "1505701               ℁    o bɔ̃ swɛ̃ də     False     préposition   \n",
       "1505702               ∴        mɔʁ‿o.vaʃ     False   symbole_num=2   \n",
       "\n",
       "                                           Audio  Pré_valide       Warn_code  \\\n",
       "1505521                                       []       False  err_lower_case   \n",
       "1505523                                       []       False  err_lower_case   \n",
       "1505609                                       []       False  err_lower_case   \n",
       "1505610                                       []       False  err_lower_case   \n",
       "1505621  [\"LL-Q150 (fra)-Penegal-Vosg'patt.wav\"]       False  err_lower_case   \n",
       "1505622                                       []       False  err_lower_case   \n",
       "1505623                                       []       False  err_lower_case   \n",
       "1505625                                       []       False  err_lower_case   \n",
       "1505627                                       []       False  err_lower_case   \n",
       "1505628                                       []       False  err_lower_case   \n",
       "1505631                                       []       False  err_lower_case   \n",
       "1505633                                       []       False  err_lower_case   \n",
       "1505635                                       []       False  err_lower_case   \n",
       "1505637                                       []       False  err_lower_case   \n",
       "1505680                                       []        True               -   \n",
       "1505692                                       []        True               -   \n",
       "1505696                                       []       False     err_letters   \n",
       "1505700                                       []       False  err_lower_case   \n",
       "1505701                                       []       False  err_lower_case   \n",
       "1505702                                       []       False  err_lower_case   \n",
       "\n",
       "                Warn_label Plausible  \n",
       "1505521  S_as_first_letter       non  \n",
       "1505523  T_as_first_letter       non  \n",
       "1505609  U_as_first_letter       non  \n",
       "1505610  U_as_first_letter       non  \n",
       "1505621  V_as_first_letter       non  \n",
       "1505622  W_as_first_letter       non  \n",
       "1505623  W_as_first_letter       non  \n",
       "1505625  X_as_first_letter       non  \n",
       "1505627  X_as_first_letter       non  \n",
       "1505628  X_as_first_letter       non  \n",
       "1505631  Y_as_first_letter       non  \n",
       "1505633  Y_as_first_letter       non  \n",
       "1505635  Y_as_first_letter       non  \n",
       "1505637  Y_as_first_letter       non  \n",
       "1505680                  -       non  \n",
       "1505692                  -       non  \n",
       "1505696                  '       non  \n",
       "1505700  €_as_first_letter       non  \n",
       "1505701  ℁_as_first_letter       non  \n",
       "1505702  ∴_as_first_letter       non  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 derniers mot dont la prononciation est détectée comme non plausible\n",
    "df2[df2.Plausible=='non'].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde des résultats KO dans fichiers .CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kq85BIVx4TCg"
   },
   "outputs": [],
   "source": [
    "# stockage des mots dot les prononciations sont non plausibles dans un fichier CSV\n",
    "df3 = df2.drop(columns=['Audio','H_aspiré','Pré_valide','Plausible'])\n",
    "df3.rename(columns = {'Err_Code':'Warn_Code', 'Err_Label':'Warn_Label'}, inplace = True)\n",
    "df3.to_csv(\"correspondances_non_trouvées.csv\", index=False, quotechar = '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# stockage des mots dont les prononciations sont non plausibles \n",
    "df4 = \"'\" + df3.Mot + \"',\"\n",
    "df4.to_csv(\"mots_non_trouvés.csv\", index=False, quotechar = '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kG2E5cw6nfT9"
   },
   "source": [
    "### Test unitaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyMUWuQmd5Lk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNE\n",
      "nɔʁnɔʁɛst\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=0, grapheme_index=0,     phonemes_hist=[], graphemes_hist=[])\n",
      "### candidate current phonemes=% ['n', 'nɔʁ']\n",
      "trying candidate current phoneme=n\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=0, grapheme_index=0) current_phoneme:n\n",
      "current_phoneme:n\n",
      "phoneme \\n\\ matching graphemes [[n]] (last_graphemes:[[nne]])\n",
      "phoneme \\n\\ matching graphemes [[nn]] (last_graphemes:[[nne]])\n",
      "phoneme \\n\\ matching graphemes [[nne]] (last_graphemes:[[nne]])\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[n]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=1, grapheme_index=1,     phonemes_hist=['n'], graphemes_hist=['n'])\n",
      "trying candidate current phoneme=ɔ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=1, grapheme_index=1) current_phoneme:ɔ\n",
      "current_phoneme:ɔ\n",
      "KO0: phonemes=\\nɔʁnɔʁɛst\\ does not match any grapheme !!!\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[nn]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=1, grapheme_index=2,     phonemes_hist=['n'], graphemes_hist=['nn'])\n",
      "trying candidate current phoneme=ɔ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=1, grapheme_index=2) current_phoneme:ɔ\n",
      "current_phoneme:ɔ\n",
      "KO0: phonemes=\\nɔʁnɔʁɛst\\ does not match any grapheme !!!\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[nne]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=1, grapheme_index=3,     phonemes_hist=['n'], graphemes_hist=['nne'])\n",
      "ended ko\n",
      "LOST2 for current_phoneme \\n\\ in process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=0, grapheme_index=0)\n",
      "move2 to next candidate phoneme\n",
      "trying candidate current phoneme=nɔʁ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=0, grapheme_index=0) current_phoneme:nɔʁ\n",
      "current_phoneme:nɔʁ\n",
      "phoneme \\nɔʁ\\ matching graphemes [[n]] (last_graphemes:[[nne]])\n",
      "trying2 current_phoneme \\nɔʁ\\ and current_graphemes [[n]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=3, grapheme_index=1,     phonemes_hist=['nɔʁ'], graphemes_hist=['n'])\n",
      "### candidate current phonemes=% ['n', 'nɔʁ']\n",
      "trying candidate current phoneme=n\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=3, grapheme_index=1) current_phoneme:n\n",
      "current_phoneme:n\n",
      "phoneme \\n\\ matching graphemes [[n]] (last_graphemes:[[ne]])\n",
      "phoneme \\n\\ matching graphemes [[ne]] (last_graphemes:[[ne]])\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[n]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=4, grapheme_index=2,     phonemes_hist=['nɔʁ', 'n'], graphemes_hist=['n', 'n'])\n",
      "trying candidate current phoneme=ɔ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=4, grapheme_index=2) current_phoneme:ɔ\n",
      "current_phoneme:ɔ\n",
      "KO0: phonemes=\\nɔʁnɔʁɛst\\ does not match any grapheme !!!\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[ne]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=4, grapheme_index=3,     phonemes_hist=['nɔʁ', 'n'], graphemes_hist=['n', 'ne'])\n",
      "ended ko\n",
      "LOST2 for current_phoneme \\n\\ in process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=3, grapheme_index=1)\n",
      "move2 to next candidate phoneme\n",
      "trying candidate current phoneme=nɔʁ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=3, grapheme_index=1) current_phoneme:nɔʁ\n",
      "current_phoneme:nɔʁ\n",
      "phoneme \\nɔʁ\\ matching graphemes [[n]] (last_graphemes:[[ne]])\n",
      "trying2 current_phoneme \\nɔʁ\\ and current_graphemes [[n]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=6, grapheme_index=2,     phonemes_hist=['nɔʁ', 'nɔʁ'], graphemes_hist=['n', 'n'])\n",
      "### candidate current phonemes=% ['ɛ', 'ɛs', 'ɛst']\n",
      "trying candidate current phoneme=ɛ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=6, grapheme_index=2) current_phoneme:ɛ\n",
      "current_phoneme:ɛ\n",
      "phoneme \\ɛ\\ matching graphemes [[e]] (last_graphemes:[[e]])\n",
      "trying2 current_phoneme \\ɛ\\ and current_graphemes [[e]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=7, grapheme_index=3,     phonemes_hist=['nɔʁ', 'nɔʁ', 'ɛ'], graphemes_hist=['n', 'n', 'e'])\n",
      "ended ko\n",
      "LOST2 for current_phoneme \\ɛ\\ in process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=6, grapheme_index=2)\n",
      "move2 to next candidate phoneme\n",
      "trying candidate current phoneme=ɛs\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=6, grapheme_index=2) current_phoneme:ɛs\n",
      "current_phoneme:ɛs\n",
      "KO0: phonemes=\\nɔʁnɔʁɛst\\ does not match any grapheme !!!\n",
      "move0 to next candidate phoneme\n",
      "trying candidate current phoneme=ɛst\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=6, grapheme_index=2) current_phoneme:ɛst\n",
      "current_phoneme:ɛst\n",
      "phoneme \\ɛst\\ matching graphemes [[e]] (last_graphemes:[[e]])\n",
      "trying2 current_phoneme \\ɛst\\ and current_graphemes [[e]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=9, grapheme_index=3,     phonemes_hist=['nɔʁ', 'nɔʁ', 'ɛst'], graphemes_hist=['n', 'n', 'e'])\n",
      "ended ok\n",
      "phonemes_hist2b: ['nɔʁ', 'nɔʁ', 'ɛst']\n",
      "graphemes_hist2b: ['n', 'n', 'e']\n",
      "current_phoneme \\ɛst\\ and current_graphemes [[e]] : worked ok\n",
      "phonemes_hist2b: ['nɔʁ', 'nɔʁ', 'ɛst']\n",
      "graphemes_hist2b: ['n', 'n', 'e']\n",
      "current_phoneme \\nɔʁ\\ and current_graphemes [[n]] : worked ok\n",
      "phonemes_hist2b: ['nɔʁ', 'nɔʁ', 'ɛst']\n",
      "graphemes_hist2b: ['n', 'n', 'e']\n",
      "current_phoneme \\nɔʁ\\ and current_graphemes [[n]] : worked ok\n",
      "NNE \\nɔʁnɔʁɛst\\ -> n,n,e \\nɔʁ,nɔʁ,ɛst\\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mot et prononciation à tester unitairement\n",
    "graphemes_phonemes='SaturneXI,sa.tyʁnɔ̃z'\n",
    "graphemes_phonemes='SMSses,ɛs.ɛm.ɛs'\n",
    "graphemes_phonemes='NNE,nɔʁ nɔ.ʁ‿ɛst'\n",
    "\n",
    "# recharger la table de correspondance si nécessaire\n",
    "reload_table = False\n",
    "if reload_table:\n",
    "    phonemes2graphemes = read_table_de_correspondance()\n",
    "    phonemes2graphemes = add_keys(phonemes2graphemes)\n",
    "\n",
    "strings = graphemes_phonemes.split(',')\n",
    "mot = strings[0]\n",
    "graphemes = mot.lower()\n",
    "phonemes = strings[1].replace('(','').replace(')','').replace('‿','').replace('.','').replace(' ','')\n",
    "\n",
    "# nettoyage des strings\n",
    "#graphemes = graphemes.replace(' ','')\n",
    "#graphemes = graphemes.replace('-','')\n",
    "#graphemes = graphemes.replace(\"’\",'')\n",
    "phonemes = phonemes.replace(' ','')\n",
    "phonemes = phonemes.replace('\\\\','')\n",
    "phonemes = phonemes.replace('.','')\n",
    "phonemes = phonemes.replace('‿','')\n",
    "phonemes = phonemes.replace('(','')\n",
    "phonemes = phonemes.replace(')','')\n",
    "print(mot)\n",
    "print(phonemes)\n",
    "# test unitaire\n",
    "check_word_pronunciation(mot, phonemes, graphemes, unit_test=True, verbose0=True, verbose1=True, verbose2=True)\n",
    "#check_word_pronunciation(mot, phonemes, graphemes, unit_test=True, verbose0=False, verbose1=False, verbose2=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "th8Jvzrpk342"
   },
   "source": [
    "## Statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2laCDmzlJJO"
   },
   "outputs": [],
   "source": [
    "# Réaliser les comptages tottax statistiques sur les correspondances \n",
    "# précédemment comptées\n",
    "dfp = make_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBkvDJgyOlj4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonème</th>\n",
       "      <th>graphème</th>\n",
       "      <th>occurences</th>\n",
       "      <th>pourcentage</th>\n",
       "      <th>exemple_1</th>\n",
       "      <th>exemple_2</th>\n",
       "      <th>exemple_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>s</td>\n",
       "      <td>c’</td>\n",
       "      <td>177</td>\n",
       "      <td>0.00</td>\n",
       "      <td>c’</td>\n",
       "      <td>c’est</td>\n",
       "      <td>c’que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>s</td>\n",
       "      <td>s’</td>\n",
       "      <td>2972</td>\n",
       "      <td>0.00</td>\n",
       "      <td>s’abader</td>\n",
       "      <td>s’abaisser</td>\n",
       "      <td>s’abaisser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>s</td>\n",
       "      <td>ç’</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ç’</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>s</td>\n",
       "      <td>c</td>\n",
       "      <td>82012</td>\n",
       "      <td>0.12</td>\n",
       "      <td>abaciste</td>\n",
       "      <td>abacistes</td>\n",
       "      <td>abandogiciel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>s</td>\n",
       "      <td>ç</td>\n",
       "      <td>10561</td>\n",
       "      <td>0.01</td>\n",
       "      <td>accoinçon</td>\n",
       "      <td>accoinçons</td>\n",
       "      <td>agaça</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>289393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>aaronisme</td>\n",
       "      <td>aaronismes</td>\n",
       "      <td>aasax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>s</td>\n",
       "      <td>sc</td>\n",
       "      <td>5328</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abscise</td>\n",
       "      <td>abscises</td>\n",
       "      <td>abscision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>s</td>\n",
       "      <td>th</td>\n",
       "      <td>135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>chrestomathie</td>\n",
       "      <td>chrestomathies</td>\n",
       "      <td>classpath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>s</td>\n",
       "      <td>x</td>\n",
       "      <td>499</td>\n",
       "      <td>0.00</td>\n",
       "      <td>antisoixantehuitard</td>\n",
       "      <td>antisoixantehuitards</td>\n",
       "      <td>auxerrois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>s</td>\n",
       "      <td>cc</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>accensa</td>\n",
       "      <td>accensai</td>\n",
       "      <td>accensaient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>s</td>\n",
       "      <td>ce</td>\n",
       "      <td>6253</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abayance</td>\n",
       "      <td>aberrance</td>\n",
       "      <td>abjuratrice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>s</td>\n",
       "      <td>sç</td>\n",
       "      <td>112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesça</td>\n",
       "      <td>acquiesçable</td>\n",
       "      <td>acquiesçables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>s</td>\n",
       "      <td>se</td>\n",
       "      <td>1865</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>abaissemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>s</td>\n",
       "      <td>ss</td>\n",
       "      <td>119361</td>\n",
       "      <td>0.18</td>\n",
       "      <td>abadassiez</td>\n",
       "      <td>abadassions</td>\n",
       "      <td>abaissassiez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>s</td>\n",
       "      <td>sse</td>\n",
       "      <td>32655</td>\n",
       "      <td>0.05</td>\n",
       "      <td>abadasse</td>\n",
       "      <td>abaissasse</td>\n",
       "      <td>abalasse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>s</td>\n",
       "      <td>sth</td>\n",
       "      <td>97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>antiasthmatique</td>\n",
       "      <td>antiasthmatique</td>\n",
       "      <td>antiasthmatiques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>28093</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abaliénation</td>\n",
       "      <td>abaliénations</td>\n",
       "      <td>abannation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>s</td>\n",
       "      <td>z</td>\n",
       "      <td>452</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abertzale</td>\n",
       "      <td>abertzale</td>\n",
       "      <td>abertzales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>s</td>\n",
       "      <td>cent</td>\n",
       "      <td>417</td>\n",
       "      <td>0.00</td>\n",
       "      <td>agacent</td>\n",
       "      <td>agencent</td>\n",
       "      <td>agoucent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>s</td>\n",
       "      <td>ces</td>\n",
       "      <td>3304</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abayances</td>\n",
       "      <td>aberrances</td>\n",
       "      <td>abjuratrices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>s</td>\n",
       "      <td>sce</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesce</td>\n",
       "      <td>acquiescemens</td>\n",
       "      <td>acquiescement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>s</td>\n",
       "      <td>scent</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiescent</td>\n",
       "      <td>concupiscent</td>\n",
       "      <td>fascent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>s</td>\n",
       "      <td>sces</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesces</td>\n",
       "      <td>concupisces</td>\n",
       "      <td>drosces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>s</td>\n",
       "      <td>sent</td>\n",
       "      <td>352</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaissent</td>\n",
       "      <td>absconsent</td>\n",
       "      <td>accensent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>s</td>\n",
       "      <td>ses</td>\n",
       "      <td>1105</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaisses</td>\n",
       "      <td>abaisses</td>\n",
       "      <td>abbesses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>s</td>\n",
       "      <td>ssent</td>\n",
       "      <td>29507</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abadassent</td>\n",
       "      <td>abaissassent</td>\n",
       "      <td>abalassent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>s</td>\n",
       "      <td>sses</td>\n",
       "      <td>29920</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abadasses</td>\n",
       "      <td>abaissasses</td>\n",
       "      <td>abalasses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>s</td>\n",
       "      <td>ths</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>classpaths</td>\n",
       "      <td>smithsonites</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>s</td>\n",
       "      <td>tz</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anetziens</td>\n",
       "      <td>trénitz</td>\n",
       "      <td>Anetz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phonème graphème  occurences  pourcentage            exemple_1  \\\n",
       "249       s       c’         177         0.00                   c’   \n",
       "250       s       s’        2972         0.00             s’abader   \n",
       "251       s       ç’           1         0.00                   ç’   \n",
       "252       s        c       82012         0.12             abaciste   \n",
       "253       s        ç       10561         0.01            accoinçon   \n",
       "254       s        s      289393         0.44            aaronisme   \n",
       "255       s       sc        5328         0.00              abscise   \n",
       "256       s       th         135         0.00        chrestomathie   \n",
       "257       s        x         499         0.00  antisoixantehuitard   \n",
       "258       s       cc          52         0.00              accensa   \n",
       "259       s       ce        6253         0.00             abayance   \n",
       "260       s       sç         112         0.00            acquiesça   \n",
       "261       s       se        1865         0.00              abaisse   \n",
       "262       s       ss      119361         0.18           abadassiez   \n",
       "263       s      sse       32655         0.05             abadasse   \n",
       "264       s      sth          97         0.00      antiasthmatique   \n",
       "265       s        t       28093         0.04         abaliénation   \n",
       "266       s        z         452         0.00            abertzale   \n",
       "267       s     cent         417         0.00              agacent   \n",
       "268       s      ces        3304         0.00            abayances   \n",
       "269       s      sce          16         0.00            acquiesce   \n",
       "270       s    scent           7         0.00          acquiescent   \n",
       "271       s     sces          10         0.00           acquiesces   \n",
       "272       s     sent         352         0.00            abaissent   \n",
       "273       s      ses        1105         0.00             abaisses   \n",
       "274       s    ssent       29507         0.04           abadassent   \n",
       "275       s     sses       29920         0.04            abadasses   \n",
       "276       s      ths           2         0.00           classpaths   \n",
       "277       s       tz          12         0.00            anetziens   \n",
       "\n",
       "                exemple_2         exemple_3  \n",
       "249                 c’est             c’que  \n",
       "250            s’abaisser        s’abaisser  \n",
       "251                                          \n",
       "252             abacistes      abandogiciel  \n",
       "253            accoinçons             agaça  \n",
       "254            aaronismes             aasax  \n",
       "255              abscises         abscision  \n",
       "256        chrestomathies         classpath  \n",
       "257  antisoixantehuitards         auxerrois  \n",
       "258              accensai       accensaient  \n",
       "259             aberrance       abjuratrice  \n",
       "260          acquiesçable     acquiesçables  \n",
       "261               abaisse       abaissemens  \n",
       "262           abadassions      abaissassiez  \n",
       "263            abaissasse          abalasse  \n",
       "264       antiasthmatique  antiasthmatiques  \n",
       "265         abaliénations        abannation  \n",
       "266             abertzale        abertzales  \n",
       "267              agencent          agoucent  \n",
       "268            aberrances      abjuratrices  \n",
       "269         acquiescemens     acquiescement  \n",
       "270          concupiscent           fascent  \n",
       "271           concupisces           drosces  \n",
       "272            absconsent         accensent  \n",
       "273              abaisses          abbesses  \n",
       "274          abaissassent        abalassent  \n",
       "275           abaissasses         abalasses  \n",
       "276          smithsonites                    \n",
       "277               trénitz             Anetz  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les statistiques d'un phonème en particulier (ex: \\s\\)\n",
    "phoneme = 's'\n",
    "#hex(ord('s'))\n",
    "dfp[dfp.phonème == phoneme]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvEujTABtn3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonème</th>\n",
       "      <th>graphème</th>\n",
       "      <th>occurences</th>\n",
       "      <th>pourcentage</th>\n",
       "      <th>exemple_1</th>\n",
       "      <th>exemple_2</th>\n",
       "      <th>exemple_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>s</td>\n",
       "      <td>c’</td>\n",
       "      <td>177</td>\n",
       "      <td>0.00</td>\n",
       "      <td>c’</td>\n",
       "      <td>c’est</td>\n",
       "      <td>c’que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>s</td>\n",
       "      <td>s’</td>\n",
       "      <td>2972</td>\n",
       "      <td>0.00</td>\n",
       "      <td>s’abader</td>\n",
       "      <td>s’abaisser</td>\n",
       "      <td>s’abaisser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>s</td>\n",
       "      <td>ç’</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ç’</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>s</td>\n",
       "      <td>c</td>\n",
       "      <td>82012</td>\n",
       "      <td>0.12</td>\n",
       "      <td>abaciste</td>\n",
       "      <td>abacistes</td>\n",
       "      <td>abandogiciel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>s</td>\n",
       "      <td>ç</td>\n",
       "      <td>10561</td>\n",
       "      <td>0.01</td>\n",
       "      <td>accoinçon</td>\n",
       "      <td>accoinçons</td>\n",
       "      <td>agaça</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>289393</td>\n",
       "      <td>0.44</td>\n",
       "      <td>aaronisme</td>\n",
       "      <td>aaronismes</td>\n",
       "      <td>aasax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>s</td>\n",
       "      <td>sc</td>\n",
       "      <td>5328</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abscise</td>\n",
       "      <td>abscises</td>\n",
       "      <td>abscision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>s</td>\n",
       "      <td>th</td>\n",
       "      <td>135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>chrestomathie</td>\n",
       "      <td>chrestomathies</td>\n",
       "      <td>classpath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>s</td>\n",
       "      <td>x</td>\n",
       "      <td>499</td>\n",
       "      <td>0.00</td>\n",
       "      <td>antisoixantehuitard</td>\n",
       "      <td>antisoixantehuitards</td>\n",
       "      <td>auxerrois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>s</td>\n",
       "      <td>cc</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>accensa</td>\n",
       "      <td>accensai</td>\n",
       "      <td>accensaient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>s</td>\n",
       "      <td>ce</td>\n",
       "      <td>6253</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abayance</td>\n",
       "      <td>aberrance</td>\n",
       "      <td>abjuratrice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>s</td>\n",
       "      <td>sç</td>\n",
       "      <td>112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesça</td>\n",
       "      <td>acquiesçable</td>\n",
       "      <td>acquiesçables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>s</td>\n",
       "      <td>se</td>\n",
       "      <td>1865</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>abaissemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>s</td>\n",
       "      <td>ss</td>\n",
       "      <td>119361</td>\n",
       "      <td>0.18</td>\n",
       "      <td>abadassiez</td>\n",
       "      <td>abadassions</td>\n",
       "      <td>abaissassiez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>s</td>\n",
       "      <td>sse</td>\n",
       "      <td>32655</td>\n",
       "      <td>0.05</td>\n",
       "      <td>abadasse</td>\n",
       "      <td>abaissasse</td>\n",
       "      <td>abalasse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>s</td>\n",
       "      <td>sth</td>\n",
       "      <td>97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>antiasthmatique</td>\n",
       "      <td>antiasthmatique</td>\n",
       "      <td>antiasthmatiques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>28093</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abaliénation</td>\n",
       "      <td>abaliénations</td>\n",
       "      <td>abannation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>s</td>\n",
       "      <td>z</td>\n",
       "      <td>452</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abertzale</td>\n",
       "      <td>abertzale</td>\n",
       "      <td>abertzales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>s</td>\n",
       "      <td>cent</td>\n",
       "      <td>417</td>\n",
       "      <td>0.00</td>\n",
       "      <td>agacent</td>\n",
       "      <td>agencent</td>\n",
       "      <td>agoucent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>s</td>\n",
       "      <td>ces</td>\n",
       "      <td>3304</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abayances</td>\n",
       "      <td>aberrances</td>\n",
       "      <td>abjuratrices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>s</td>\n",
       "      <td>sce</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesce</td>\n",
       "      <td>acquiescemens</td>\n",
       "      <td>acquiescement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>s</td>\n",
       "      <td>scent</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiescent</td>\n",
       "      <td>concupiscent</td>\n",
       "      <td>fascent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>s</td>\n",
       "      <td>sces</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesces</td>\n",
       "      <td>concupisces</td>\n",
       "      <td>drosces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>s</td>\n",
       "      <td>sent</td>\n",
       "      <td>352</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaissent</td>\n",
       "      <td>absconsent</td>\n",
       "      <td>accensent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>s</td>\n",
       "      <td>ses</td>\n",
       "      <td>1105</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaisses</td>\n",
       "      <td>abaisses</td>\n",
       "      <td>abbesses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>s</td>\n",
       "      <td>ssent</td>\n",
       "      <td>29507</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abadassent</td>\n",
       "      <td>abaissassent</td>\n",
       "      <td>abalassent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>s</td>\n",
       "      <td>sses</td>\n",
       "      <td>29920</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abadasses</td>\n",
       "      <td>abaissasses</td>\n",
       "      <td>abalasses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>s</td>\n",
       "      <td>ths</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>classpaths</td>\n",
       "      <td>smithsonites</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>s</td>\n",
       "      <td>tz</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anetziens</td>\n",
       "      <td>trénitz</td>\n",
       "      <td>Anetz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phonème graphème  occurences  pourcentage            exemple_1  \\\n",
       "249       s       c’         177         0.00                   c’   \n",
       "250       s       s’        2972         0.00             s’abader   \n",
       "251       s       ç’           1         0.00                   ç’   \n",
       "252       s        c       82012         0.12             abaciste   \n",
       "253       s        ç       10561         0.01            accoinçon   \n",
       "254       s        s      289393         0.44            aaronisme   \n",
       "255       s       sc        5328         0.00              abscise   \n",
       "256       s       th         135         0.00        chrestomathie   \n",
       "257       s        x         499         0.00  antisoixantehuitard   \n",
       "258       s       cc          52         0.00              accensa   \n",
       "259       s       ce        6253         0.00             abayance   \n",
       "260       s       sç         112         0.00            acquiesça   \n",
       "261       s       se        1865         0.00              abaisse   \n",
       "262       s       ss      119361         0.18           abadassiez   \n",
       "263       s      sse       32655         0.05             abadasse   \n",
       "264       s      sth          97         0.00      antiasthmatique   \n",
       "265       s        t       28093         0.04         abaliénation   \n",
       "266       s        z         452         0.00            abertzale   \n",
       "267       s     cent         417         0.00              agacent   \n",
       "268       s      ces        3304         0.00            abayances   \n",
       "269       s      sce          16         0.00            acquiesce   \n",
       "270       s    scent           7         0.00          acquiescent   \n",
       "271       s     sces          10         0.00           acquiesces   \n",
       "272       s     sent         352         0.00            abaissent   \n",
       "273       s      ses        1105         0.00             abaisses   \n",
       "274       s    ssent       29507         0.04           abadassent   \n",
       "275       s     sses       29920         0.04            abadasses   \n",
       "276       s      ths           2         0.00           classpaths   \n",
       "277       s       tz          12         0.00            anetziens   \n",
       "\n",
       "                exemple_2         exemple_3  \n",
       "249                 c’est             c’que  \n",
       "250            s’abaisser        s’abaisser  \n",
       "251                                          \n",
       "252             abacistes      abandogiciel  \n",
       "253            accoinçons             agaça  \n",
       "254            aaronismes             aasax  \n",
       "255              abscises         abscision  \n",
       "256        chrestomathies         classpath  \n",
       "257  antisoixantehuitards         auxerrois  \n",
       "258              accensai       accensaient  \n",
       "259             aberrance       abjuratrice  \n",
       "260          acquiesçable     acquiesçables  \n",
       "261               abaisse       abaissemens  \n",
       "262           abadassions      abaissassiez  \n",
       "263            abaissasse          abalasse  \n",
       "264       antiasthmatique  antiasthmatiques  \n",
       "265         abaliénations        abannation  \n",
       "266             abertzale        abertzales  \n",
       "267              agencent          agoucent  \n",
       "268            aberrances      abjuratrices  \n",
       "269         acquiescemens     acquiescement  \n",
       "270          concupiscent           fascent  \n",
       "271           concupisces           drosces  \n",
       "272            absconsent         accensent  \n",
       "273              abaisses          abbesses  \n",
       "274          abaissassent        abalassent  \n",
       "275           abaissasses         abalasses  \n",
       "276          smithsonites                    \n",
       "277               trénitz             Anetz  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp[dfp.phonème == phoneme]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LTLaTRWYJn2r"
   },
   "source": [
    "## Bilan des correspondances non trouvées\n",
    "\n",
    "* Normalement, aucune ligne ne devrait être affichée (si noms communs, noms propres et sigles analysés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Df8fmZunHd7r"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonème</th>\n",
       "      <th>graphème</th>\n",
       "      <th>occurences</th>\n",
       "      <th>pourcentage</th>\n",
       "      <th>exemple_1</th>\n",
       "      <th>exemple_2</th>\n",
       "      <th>exemple_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>ɥ</td>\n",
       "      <td>’hu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>532</td>\n",
       "      <td>ɛ</td>\n",
       "      <td>eighs</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>œ̃</td>\n",
       "      <td>Hun</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>œ̃</td>\n",
       "      <td>Huns</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605</td>\n",
       "      <td>œ</td>\n",
       "      <td>ogl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>619</td>\n",
       "      <td>ø</td>\n",
       "      <td>hœ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>627</td>\n",
       "      <td>ø</td>\n",
       "      <td>euent</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>747</td>\n",
       "      <td>o</td>\n",
       "      <td>hoa</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>ɑ̃</td>\n",
       "      <td>aën</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>916</td>\n",
       "      <td>a</td>\n",
       "      <td>acts</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>944</td>\n",
       "      <td>aj</td>\n",
       "      <td>j</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>945</td>\n",
       "      <td>aj</td>\n",
       "      <td>igh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958</td>\n",
       "      <td>ɡz</td>\n",
       "      <td>xh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>959</td>\n",
       "      <td>ɔɛ</td>\n",
       "      <td>œ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>tʃ</td>\n",
       "      <td>ch</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>962</td>\n",
       "      <td>tʃ</td>\n",
       "      <td>œ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1021</td>\n",
       "      <td>dissɛt</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1022</td>\n",
       "      <td>dissɛt</td>\n",
       "      <td>xvii</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1026</td>\n",
       "      <td>disnœf</td>\n",
       "      <td>xix</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     phonème graphème  occurences  pourcentage exemple_1 exemple_2 exemple_3\n",
       "380        ɥ      ’hu           0          0.0                              \n",
       "532        ɛ    eighs           0          0.0                              \n",
       "584       œ̃      Hun           0          0.0                              \n",
       "585       œ̃     Huns           0          0.0                              \n",
       "605        œ      ogl           0          0.0                              \n",
       "619        ø       hœ           0          0.0                              \n",
       "627        ø    euent           0          0.0                              \n",
       "747        o      hoa           0          0.0                              \n",
       "846       ɑ̃      aën           0          0.0                              \n",
       "916        a     acts           0          0.0                              \n",
       "944       aj        j           0          0.0                              \n",
       "945       aj      igh           0          0.0                              \n",
       "958       ɡz       xh           0          0.0                              \n",
       "959       ɔɛ        œ           0          0.0                              \n",
       "960       tʃ       ch           0          0.0                              \n",
       "962       tʃ        œ           0          0.0                              \n",
       "1021  dissɛt       17           0          0.0                              \n",
       "1022  dissɛt     xvii           0          0.0                              \n",
       "1026  disnœf      xix           0          0.0                              "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "dfp[dfp.occurences == 0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "test_de_plausibité.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
