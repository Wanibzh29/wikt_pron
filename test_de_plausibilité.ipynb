{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OcBwaujqj7wg"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Ce programme a pour but de tester la plausibilité de la prononciation d'un mot telle qu'indiquée sur le Wiktionnaire.\n",
    "\n",
    "Pour ce faire, il parcours itérativement les différents sons (phonemes) d'un mot et essaie les différentes lettres (graphemes) pouvant être utilisées pour écrire le son (grâce à une table de correspondance similaire à https://fr.wiktionary.org/wiki/Annexe:Prononciation/français#Troisième_approche). A chaque essai, il compare ce qu'il obtient avec l'orthographe utilisée dans le Wiktionnaire. Lorsqu'il arrive au même résultat, la prononciation du mot est jugée plausible. A l'inverse, s'il n'arrive pas à transcrire la même orthographe que celle indiquée dans le Wiktionnaire, la prononciation est jugée suspecte.\n",
    "\n",
    "Ce programme peut aussi compter les différentes lettres utilisées pour transcrire un son. Ainsi, s'il est executé sur tous les mots du Wiktionnaire, il peut servir à compter les probabilités de ces lettres pour transcrire un son donné.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8iczXUEW6x1g"
   },
   "source": [
    "## Données d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zD26Opi6hhPK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading  https://fonétik.fr/fr_wiktionary_full.csv\n"
     ]
    }
   ],
   "source": [
    "# importation des librairies tierces\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def add_words(df, mot, prononciation, type='à-faire'):\n",
    "  df = df.append(dict(zip(['Mot', 'Prononciation', 'H_aspiré', 'Type', 'Pré_valide', 'Err_Code', 'Err_Label'],\n",
    "                          [mot, prononciation, 0.0, type, 1.0, '-', '-'])), ignore_index=True)\n",
    "  return df\n",
    "\n",
    "# lecture des données d'entrée (ligne contenant un mot du dictionnaire\n",
    "# ainsi que sa prononciation\n",
    "def read_df():\n",
    "\n",
    "  '''Read the input data (i.e. lines containing a Wiktionary word \n",
    "  and its pronunciation) '''\n",
    "  filename = 'fr_wiktionary_full.csv'\n",
    "    \n",
    "  filepath = Path(filename)\n",
    "\n",
    "  url = 'https://fonétik.fr/'\n",
    "  url_filename = url + filename\n",
    "\n",
    "  print('downloading ', url_filename)\n",
    "  # if file not found locally, then download it\n",
    "  if not filepath.exists():\n",
    "    !wget -N -q {url_filename}\n",
    "\n",
    "  df = pd.read_csv(filename, keep_default_na=False, sep = '\\t')\n",
    "\n",
    "  #Ajout de mots absents du fichier d'input à cause de leur valeur\n",
    "  #en conflit avec une lirairie python\n",
    "  missing_words = [\n",
    "                   ('naan', 'nan', 'nom'),\n",
    "                   ('naans', 'nan', 'nom_flexion'),\n",
    "                   ('na', 'na', 'particule'),\n",
    "                   ('na', 'na', 'interjection'),\n",
    "  ]\n",
    "  #for w in missing_words:\n",
    "  #  df = add_words(df, w[0], w[1], w[2])\n",
    "  \n",
    "  # Ajout de certains prononciations de mots non-présentes dans les entrées\n",
    "  # (manque la 2ème prononciation dans le csv)\n",
    "  temporary_words  = [#('argh', 'aʁ'),\n",
    "                      ('bobsleigh', 'bɔbslɛ'),\n",
    "                      ('bobsleighs', 'bɔbslɛ'),\n",
    "                      ('os', 'o'),\n",
    "                      #('résumpte', 'ʁezɔ̃t'),\n",
    "                      #('exact', 'ɛɡza'),\n",
    "                      #('exacts', 'ɛɡza'),\n",
    "                       # should be in next version of csv\n",
    "                      ('trapp', 'tʁap'),\n",
    "                      ('trapps', 'tʁap'),\n",
    "                      ('judd', 'ʒud'),\n",
    "                      ('judds', 'ʒud'),\n",
    "                      ('jodhs', 'jɔd'),\n",
    "                      ('yachtsman', 'jɔtman'),\n",
    "                      ('gonzs','ɡɔ̃z'),\n",
    "                      ('hés','e'),\n",
    "                      ('eins','ɛ̃'),\n",
    "                      ('aveuent','avœ'),\n",
    "                      ('hient','i'),\n",
    "                      ('huent','y'),\n",
    "                      ('hues','y'),\n",
    "                      ('eaux-fortes','ofɔʁt'),\n",
    "                      ('hauts-fonds','ofɔ̃'),\n",
    "                      ('hoax','oks'),\n",
    "                      ('curaçao','kyʁaso'),\n",
    "                      ('curaçaos','kyʁaso'),\n",
    "                      ('wisigoths','viziɡɔ'),\n",
    "                      ('wisigoth','viziɡo'),\n",
    "                      ('wisigoths','viziɡo'),\n",
    "                      ('hon','ɔ̃'),\n",
    "                      ('exempts','ɛɡzɑ̃'),\n",
    "                      ('ah','a'),\n",
    "                      ('s’', 's'),\n",
    "\n",
    "  ]\n",
    "  for temporary_word in temporary_words:\n",
    "    df = add_words(df, temporary_word[0], temporary_word[1])\n",
    "\n",
    "  return df\n",
    "\n",
    "df = read_df()\n",
    "df.rename(columns = {'Err_Code':'Warn_Code', 'Err_Label':'Warn_Label'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "e8LX-nHWXKQg",
    "outputId": "3d969ca8-f285-451a-cf15-4ff81bdd3c6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_Code</th>\n",
       "      <th>Warn_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1484038</td>\n",
       "      <td>wisigoths</td>\n",
       "      <td>viziɡo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>à-faire</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1484039</td>\n",
       "      <td>hon</td>\n",
       "      <td>ɔ̃</td>\n",
       "      <td>0.0</td>\n",
       "      <td>à-faire</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1484040</td>\n",
       "      <td>exempts</td>\n",
       "      <td>ɛɡzɑ̃</td>\n",
       "      <td>0.0</td>\n",
       "      <td>à-faire</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1484041</td>\n",
       "      <td>ah</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>à-faire</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1484042</td>\n",
       "      <td>s’</td>\n",
       "      <td>s</td>\n",
       "      <td>0.0</td>\n",
       "      <td>à-faire</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mot Prononciation  H_aspiré     Type  Pré_valide Warn_Code  \\\n",
       "1484038  wisigoths        viziɡo       0.0  à-faire         1.0         -   \n",
       "1484039        hon            ɔ̃       0.0  à-faire         1.0         -   \n",
       "1484040    exempts         ɛɡzɑ̃       0.0  à-faire         1.0         -   \n",
       "1484041         ah             a       0.0  à-faire         1.0         -   \n",
       "1484042         s’             s       0.0  à-faire         1.0         -   \n",
       "\n",
       "        Warn_Label  \n",
       "1484038          -  \n",
       "1484039          -  \n",
       "1484040          -  \n",
       "1484041          -  \n",
       "1484042          -  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PmidCDRIAwl"
   },
   "outputs": [],
   "source": [
    "# corriger les & mal-formatés s'il y a en\n",
    "df['Mot'] = df['Mot'].str.replace('&amp;', '&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XIBkXvacY5sH",
    "outputId": "4c4b2df2-7a5a-4fc7-d528-7a2fc982de78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1484043"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage du nombre d'échantillons en entrées\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "COxsRMd09a1s"
   },
   "outputs": [],
   "source": [
    "df['Plausible'] = '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "fGy2OiKXEkQm",
    "outputId": "d5299641-eec8-4f01-df56-a86be98911eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_Code</th>\n",
       "      <th>Warn_Label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>868728</td>\n",
       "      <td>peluchais</td>\n",
       "      <td>ply.ʃɛ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>verbe_flexion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1102828</td>\n",
       "      <td>renvahi</td>\n",
       "      <td>ʁɑ̃.va.i</td>\n",
       "      <td>0.0</td>\n",
       "      <td>verbe_flexion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75711</td>\n",
       "      <td>amanite étranglée</td>\n",
       "      <td>a.ma.nit e.tʁɑ̃.ɡle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714600</td>\n",
       "      <td>inéclairci</td>\n",
       "      <td>i.ne.klɛʁ.si</td>\n",
       "      <td>0.0</td>\n",
       "      <td>adjectif</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145681</td>\n",
       "      <td>auto-traînât</td>\n",
       "      <td>o.to.tʁɛ.na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>verbe_flexion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Mot        Prononciation  H_aspiré           Type  \\\n",
       "868728           peluchais               ply.ʃɛ       0.0  verbe_flexion   \n",
       "1102828            renvahi             ʁɑ̃.va.i       0.0  verbe_flexion   \n",
       "75711    amanite étranglée  a.ma.nit e.tʁɑ̃.ɡle       0.0            nom   \n",
       "714600          inéclairci         i.ne.klɛʁ.si       0.0       adjectif   \n",
       "145681        auto-traînât          o.to.tʁɛ.na       0.0  verbe_flexion   \n",
       "\n",
       "         Pré_valide Warn_Code Warn_Label Plausible  \n",
       "868728          1.0         -          -         ?  \n",
       "1102828         1.0         -          -         ?  \n",
       "75711           1.0         -          -         ?  \n",
       "714600          1.0         -          -         ?  \n",
       "145681          1.0         -          -         ?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage de 5 derniers échantillons\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "su8M2cf-AGNl",
    "outputId": "9b4be442-25bf-4745-e68e-4b23b8bca0c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_Code</th>\n",
       "      <th>Warn_Label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1248966</td>\n",
       "      <td>résumpte</td>\n",
       "      <td>ʁe.zɔ̃pt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mot Prononciation  H_aspiré Type  Pré_valide Warn_Code  \\\n",
       "1248966  résumpte      ʁe.zɔ̃pt       0.0  nom         1.0         -   \n",
       "\n",
       "        Warn_Label Plausible  \n",
       "1248966          -         ?  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Mot=='résumpte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpcCm53fcXVl"
   },
   "source": [
    "## Table de correspondance entre sons et lettres\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def read_table_de_correspondance():\n",
    "    df = pd.read_csv(\"table_de_correspondances.csv\")\n",
    "    phonemes2graphemes = {}\n",
    "    for phoneme in df.Phonème.values:\n",
    "        for position in df[df.Phonème == phoneme].Position.values:\n",
    "            for grapheme in df[df.Phonème == phoneme][df.Position == position].Graphème.values:\n",
    "                if phoneme not in phonemes2graphemes.keys():\n",
    "                    phonemes2graphemes[phoneme] = {}\n",
    "                phonemes2graphemes[phoneme][grapheme] = {}\n",
    "            \n",
    "    return phonemes2graphemes\n",
    "\n",
    "phonemes2graphemes = read_table_de_correspondance()\n",
    "\n",
    "def add_keys(phonemes2graphemes):\n",
    "  '''Ajoute des clés ('occurences', 'exemple_1', 'exemple_2', 'exemple_3')\n",
    "   dans le dictionnaire de chaque grapheme de la table phonemes2graphemes.'''\n",
    "\n",
    "  for phoneme in phonemes2graphemes.keys():\n",
    "    #for position in phonemes2graphemes[phoneme].keys():\n",
    "      for grapheme in phonemes2graphemes[phoneme].keys():\n",
    "        phonemes2graphemes[phoneme][grapheme]['occurences'] = 0\n",
    "        phonemes2graphemes[phoneme][grapheme]['exemple_1'] = ''\n",
    "        phonemes2graphemes[phoneme][grapheme]['exemple_2'] = ''\n",
    "        phonemes2graphemes[phoneme][grapheme]['exemple_3'] = ''\n",
    "\n",
    "  return phonemes2graphemes\n",
    "\n",
    "# run add_keys\n",
    "phonemes2graphemes = add_keys(phonemes2graphemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsDUfNANiXDs"
   },
   "source": [
    "## Fonctions de comptage pour statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-r1cTpGHmAso"
   },
   "outputs": [],
   "source": [
    "# fonction de comptage qui incrémente d'une unité le compteur de correspondance\n",
    "# entre un phonème donné et un graphème donné et qui enregistre en exemple \n",
    "# les trois premiers mots dans lequels la correspondance a été trouvé \n",
    "def increment_occurences(phoneme, grapheme, mot, unit_test=False):\n",
    "  \n",
    "  global phonemes2graphemes\n",
    "\n",
    "  # ne pas continuer si l'appel provient d'un test unitaire\n",
    "  if unit_test:\n",
    "    return\n",
    "\n",
    "  phonemes2graphemes[phoneme][grapheme]['occurences']  += 1\n",
    "  if phonemes2graphemes[phoneme][grapheme]['exemple_1']  == '':\n",
    "    phonemes2graphemes[phoneme][grapheme]['exemple_1'] = mot\n",
    "  elif phonemes2graphemes[phoneme][grapheme]['exemple_2']  == '':\n",
    "    phonemes2graphemes[phoneme][grapheme]['exemple_2'] = mot\n",
    "  elif phonemes2graphemes[phoneme][grapheme]['exemple_3']  == '':\n",
    "    phonemes2graphemes[phoneme][grapheme]['exemple_3'] = mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "nNXz97yImhDC",
    "outputId": "8ad76acb-a3d3-4526-b185-a14aa62197e4"
   },
   "outputs": [],
   "source": [
    "# fonction de statistiques qui calcule pour pour chaque position (initiale,\n",
    "# intermédiaire ou finale) le nombre d'occurences de chaque graphème ainsi\n",
    "# que la probabilité de ce graphème.\n",
    "# Les résultats sont insérés dans un DataFrame pandas et dans un fichier CSV.\n",
    "\n",
    "def make_stats():\n",
    "  global phonemes2graphemes\n",
    "\n",
    "  table = []\n",
    "  for phoneme in phonemes2graphemes:\n",
    "      for grapheme in phonemes2graphemes[phoneme].keys():\n",
    "        occurences = phonemes2graphemes[phoneme][grapheme]['occurences']\n",
    "        exemple_1 = phonemes2graphemes[phoneme][grapheme]['exemple_1']\n",
    "        exemple_2 = phonemes2graphemes[phoneme][grapheme]['exemple_2']\n",
    "        exemple_3 = phonemes2graphemes[phoneme][grapheme]['exemple_3']\n",
    "\n",
    "        #print(\"phoneme=%s grapheme=%s occurences=%d\" % (phoneme, grapheme, occurences))\n",
    "        row = { 'phonème': phoneme, 'graphème':grapheme, 'occurences':occurences, 'pourcentage':0.0,\n",
    "               'exemple_1' : exemple_1, 'exemple_2' : exemple_2, 'exemple_3' : exemple_3, }\n",
    "        table.append(row)\n",
    "  dfp = pd.DataFrame.from_dict(table)\n",
    "\n",
    "  for phoneme in dfp['phonème'].unique():\n",
    "      df1 = dfp[dfp['phonème'] == phoneme]\n",
    "\n",
    "      # calculate the sum of used graphemes within each phoneme-position category\n",
    "      sum = 0\n",
    "      for grapheme in df1['graphème'].unique():\n",
    "        row_number = df1.loc[df1.graphème==grapheme].index[0]\n",
    "        occurences = df1.at[row_number, 'occurences']\n",
    "        sum += occurences\n",
    "\n",
    "      # set the pourcentage of each graphemes for each phoneme-position category\n",
    "      if sum != 0:\n",
    "        for grapheme in df1['graphème'].unique():\n",
    "          row_number = df1.loc[df1.graphème==grapheme].index[0]\n",
    "          occurences = df1.at[row_number, 'occurences']\n",
    "          pourcentage = int(occurences/sum*100)/100\n",
    "          dfp.at[row_number, 'pourcentage'] = pourcentage\n",
    "\n",
    "      dfp.to_csv(\"phonemes2graphemes.csv\", index=False)\n",
    "\n",
    "  return dfp\n",
    "\n",
    "_ = make_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1v0fIw3nuU8"
   },
   "source": [
    "## Fonction de test de plausibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeQZ2cWYoCQG"
   },
   "outputs": [],
   "source": [
    "# Fonction récursive tentant de retrouver tout ou partie des graphemes\n",
    "# depuis tout ou partie des phonemes, à l'aide de la table de correspondance\n",
    "# entre les phonemes et les graphemes.\n",
    "\n",
    "def process_graphemes(mot, phonemes, graphemes, \n",
    "                      phoneme_index=0, grapheme_index=0, \n",
    "                      phonemes_hist='', graphemes_hist='', \n",
    "                      unit_test = False, verbose=False,):\n",
    "  \n",
    "  if verbose:\n",
    "    print('')\n",
    "    print('process_graphemes(phonemes=\\\\%s\\\\, graphemes=[[%s]], \\\n",
    "    phoneme_index=%d, grapheme_index=%d, \\\n",
    "    phonemes_hist=%s, graphemes_hist=%s)' \n",
    "            % (phonemes, graphemes, phoneme_index, grapheme_index, phonemes_hist, graphemes_hist))\n",
    "\n",
    "  global phonemes2graphemes\n",
    "\n",
    "  if grapheme_index >= len(graphemes):\n",
    "    if ''.join(graphemes_hist) == graphemes and ''.join(phonemes_hist)==phonemes:\n",
    "        if verbose:\n",
    "            print('ended ok')            \n",
    "        return True, phonemes_hist.copy(), graphemes_hist.copy()\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('ended ko')\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "\n",
    "  current_candidate_phonemes = []\n",
    "  for phoneme in phonemes2graphemes:    \n",
    "    if phonemes[phoneme_index:].startswith(phoneme):      \n",
    "      current_candidate_phonemes.append(phoneme)\n",
    "  if len(current_candidate_phonemes) == 0:\n",
    "    return False, phonemes_hist, graphemes_hist\n",
    "  if verbose:\n",
    "    if len(current_candidate_phonemes) > 1:\n",
    "      print(\"### candidate current phonemes=%\", current_candidate_phonemes)\n",
    "\n",
    "  nb_current_candidate_phonemes = 0 \n",
    "\n",
    "  for current_phoneme in current_candidate_phonemes:\n",
    "    if verbose:\n",
    "      print(\"trying candidate current phoneme=%s\" % current_phoneme)\n",
    "    nb_current_candidate_phonemes += 1\n",
    "    next_phoneme = ''\n",
    "\n",
    "    last_graphemes = graphemes[grapheme_index:]\n",
    "    \n",
    "    if verbose:\n",
    "      print('process_graphemes(phonemes=\\\\%s\\\\, graphemes=[[%s]], phoneme_index=%d, grapheme_index=%d) current_phoneme:%s' \n",
    "            % (phonemes, graphemes, phoneme_index, grapheme_index, current_phoneme))\n",
    "  \n",
    "    if verbose:\n",
    "      print('current_phoneme:%s' % current_phoneme)\n",
    "    \n",
    "    try:\n",
    "      len(phonemes2graphemes[current_phoneme])\n",
    "    except:\n",
    "      a=1\n",
    "      if current_phoneme == '':\n",
    "        if verbose:\n",
    "          print('wrn: in [[%s]] : phoneme \\\\%s\\\\ does not exist !!!' % (graphemes, current_phoneme))\n",
    "        return True, phonemes_hist, graphemes_hist\n",
    "      else:\n",
    "        print('err: in [[%s]] : phoneme \\\\%s\\\\ does not exist !!!' % (graphemes, current_phoneme))\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "\n",
    "    matching_graphemes_list = []\n",
    "\n",
    "    for current_graphemes in phonemes2graphemes[current_phoneme]:\n",
    "    \n",
    "      if last_graphemes.startswith(current_graphemes):\n",
    "        if verbose:\n",
    "          print('phoneme \\\\%s\\\\ matching graphemes [[%s]] (last_graphemes:[[%s]])' % (current_phoneme, current_graphemes, last_graphemes))\n",
    "        matching_graphemes_list.append(current_graphemes)\n",
    "\n",
    "    if len(matching_graphemes_list) == 0:\n",
    "      if verbose:\n",
    "        print('KO0: phonemes=\\\\%s\\\\ does not match any grapheme !!!' % (phonemes))\n",
    "\n",
    "      if nb_current_candidate_phonemes == len(current_candidate_phonemes):\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "      else:\n",
    "        if verbose:\n",
    "          print('move0 to next candidate phoneme')\n",
    "        continue\n",
    "      \n",
    "    #print('current_phoneme=', current_phoneme)\n",
    "    \n",
    "    ### * ###\n",
    "    if len(matching_graphemes_list) == 0:\n",
    "        if verbose:\n",
    "          print('KO: phoneme \\\\%s\\\\ matches NO grapheme (in word [[%s]])  !!!' % (graphemes, phonemes))\n",
    "        phonemes_hist.pop()\n",
    "        graphemes_hist.pop()\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "\n",
    "    for current_graphemes in matching_graphemes_list:\n",
    "        \n",
    "        phonemes_hist.append(current_phoneme)\n",
    "        graphemes_hist.append(current_graphemes)\n",
    "\n",
    "        if verbose:\n",
    "          print(\"trying2 current_phoneme \\\\%s\\\\ and current_graphemes [[%s]]\" % (current_phoneme, current_graphemes))\n",
    "\n",
    "        ret, phonemes_hist2, graphemes_hist2 = process_graphemes(\n",
    "            mot,\n",
    "            phonemes, \n",
    "            graphemes,\n",
    "            phoneme_index=phoneme_index+len(current_phoneme), \n",
    "            grapheme_index=grapheme_index+len(current_graphemes),\n",
    "            phonemes_hist = phonemes_hist,\n",
    "            graphemes_hist = graphemes_hist,\n",
    "            unit_test = unit_test,\n",
    "            verbose=verbose)           \n",
    "                \n",
    "        # si la concatenation des graphemes trouvées jusqu'ici n'est pas bonne, alors pas bon\n",
    "        if not graphemes.startswith(''.join(graphemes_hist)):\n",
    "            if verbose:\n",
    "                print(''.join(graphemes_hist)+current_graphemes)\n",
    "                print(graphemes)\n",
    "                print('current_graphemes does not match previous findings')\n",
    "            ret = False          \n",
    "                \n",
    "          # si la concatenation des graphemes trouvées jusqu'ici n'est pas bonne, alors pas bon\n",
    "\n",
    "      \n",
    "        if ret == True:\n",
    "          if verbose:\n",
    "            print('phonemes_hist2b:', phonemes_hist2)\n",
    "            print('graphemes_hist2b:', graphemes_hist2)\n",
    "            print(\"current_phoneme \\\\%s\\\\ and current_graphemes [[%s]] : worked ok\" % (current_phoneme, current_graphemes))\n",
    "          \n",
    "          increment_occurences(current_phoneme, current_graphemes, mot, unit_test)\n",
    "          return True, phonemes_hist2, graphemes_hist2\n",
    "    \n",
    "        phonemes_hist.pop()\n",
    "        graphemes_hist.pop()\n",
    "      \n",
    "    # if here LOST\n",
    "    if verbose:\n",
    "          print('LOST2 for current_phoneme \\\\%s\\\\ in process_graphemes(phonemes=\\\\%s\\\\, graphemes=[[%s]], phoneme_index=%d, grapheme_index=%d)' \n",
    "                % (current_phoneme, phonemes, graphemes, phoneme_index, grapheme_index))\n",
    "    \n",
    "    if nb_current_candidate_phonemes == len(current_candidate_phonemes):\n",
    "        return False, phonemes_hist2, graphemes_hist2\n",
    "    else:\n",
    "       \n",
    "        if verbose:\n",
    "          print('move2 to next candidate phoneme')\n",
    "        continue\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ZlfYwF1opiA"
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOS9qKRWzO42"
   },
   "source": [
    "### Exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhYXjOSbo9_I"
   },
   "outputs": [],
   "source": [
    "exemples = [\n",
    "    (\"momie\", \"mɔmi\"),\n",
    "    (\"pookie\", \"puki\"),\n",
    "\n",
    "]\n",
    "\n",
    "for exemple in exemples:\n",
    "    \n",
    "    mot = exemple[0]\n",
    "    graphemes = exemple[0]\n",
    "    phonemes = exemple[1]\n",
    "    \n",
    "    res = process_graphemes(mot, phonemes, graphemes, \n",
    "                            phoneme_index=0, grapheme_index=0, \n",
    "                            phonemes_hist=[], graphemes_hist=[],\n",
    "                            unit_test=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uh0wZe67re4Z"
   },
   "outputs": [],
   "source": [
    "def check_word_pronunciation(mot, phonemes, graphemes, unit_test=False, verbose0=False, verbose1=False, verbose2=False):\n",
    "\n",
    "    res, phonemes2, graphemes2  = process_graphemes(mot, phonemes, graphemes, phoneme_index=0, grapheme_index=0, phonemes_hist=[], graphemes_hist=[], unit_test=unit_test, verbose=verbose2)\n",
    "    prononciation = ''.join(phonemes2)\n",
    "    word = ''.join(graphemes2)\n",
    "    prononciation_ = ','.join(phonemes2)\n",
    "    word_ = ','.join(graphemes2)\n",
    "    if prononciation != phonemes:\n",
    "      if verbose0:\n",
    "        print('[[%s]] \\\\%s\\\\ -> prononciation=\\\\%s\\\\ ' % (mot, phonemes, prononciation ))\n",
    "      return False\n",
    "    elif word != graphemes.replace('-','').replace(' ',''):\n",
    "      if verbose0:\n",
    "        print('[[%s]] != output graphemes=%s' % (mot, word))\n",
    "      return True\n",
    "    else:\n",
    "      if verbose0:\n",
    "        print('%s \\\\%s\\\\ -> %s \\\\%s\\\\' % (mot, prononciation, word_, prononciation_))\n",
    "      return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXWXcxH2xf-A"
   },
   "source": [
    "### Tests de référence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "4CZD_l1chhQO",
    "outputId": "6b3a727a-dd48-46fc-ff70-7b99fe30cb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acéphalobrache \\asefalɔbʁak\\ -> a,c,é,ph,a,l,o,b,r,a,che \\a,s,e,f,a,l,ɔ,b,ʁ,a,k\\\n",
      "acquaintance \\akwɛ̃tɑ̃s\\ -> a,cq,u,ain,t,an,ce \\a,k,w,ɛ̃,t,ɑ̃,s\\\n",
      "agoua \\aɡwa\\ -> a,g,ou,a \\a,ɡ,w,a\\\n",
      "bêchâmes \\beʃam\\ -> b,ê,ch,â,mes \\b,e,ʃ,a,m\\\n",
      "caouanne \\kawan\\ -> c,a,ou,a,nne \\k,a,w,a,n\\\n",
      "designer \\dizajnœʁ\\ -> d,e,s,i,g,n,e,r \\d,i,z,a,j,n,œ,ʁ\\\n",
      "désembouteillions \\dezɑ̃butɛjɔ̃\\ -> d,é,s,em,b,ou,t,e,illi,ons \\d,e,z,ɑ̃,b,u,t,ɛ,j,ɔ̃\\\n",
      "disjonctés \\diʒɔ̃kte\\ -> d,is,j,on,c,t,és \\d,i,ʒ,ɔ̃,k,t,e\\\n",
      "droitismes \\dʁwatism\\ -> d,r,o,i,t,i,s,mes \\d,ʁ,w,a,t,i,s,m\\\n",
      "élégante \\eleɡɑ̃t\\ -> é,l,é,g,an,te \\e,l,e,ɡ,ɑ̃,t\\\n",
      "enarrhas \\ɑ̃naʁa\\ -> e,n,a,rrh,as \\ɑ̃,n,a,ʁ,a\\\n",
      "enfutailler \\ɑ̃fytɑje\\ -> en,f,u,t,a,ill,er \\ɑ̃,f,y,t,ɑ,j,e\\\n",
      "excaverai \\ɛkskavəʁe\\ -> e,x,c,a,v,e,r,ai \\ɛ,ks,k,a,v,ə,ʁ,e\\\n",
      "exemple \\ɛɡzɑ̃pl\\ -> e,x,em,p,le \\ɛ,ɡz,ɑ̃,p,l\\\n",
      "fashion \\faʃœn\\ -> f,a,sh,io,n \\f,a,ʃ,œ,n\\\n",
      "khartoumisé \\kaʁtumize\\ -> k,ha,r,t,ou,m,i,s,é \\k,a,ʁ,t,u,m,i,z,e\\\n",
      "hauts \\o\\ -> hauts \\o\\\n",
      "hauts-fonds \\ofɔ̃\\ -> hauts,f,onds \\o,f,ɔ̃\\\n",
      "html \\aʃteɛmɛl\\ -> h,t,m,l \\aʃ,te,ɛm,ɛl\\\n",
      "intérêt \\ɛ̃teʁɛ\\ -> in,t,é,r,êt \\ɛ̃,t,e,ʁ,ɛ\\\n",
      "intéressant \\ɛ̃teʁɛsɑ̃\\ -> in,t,é,r,es,s,ant \\ɛ̃,t,e,ʁ,ɛ,s,ɑ̃\\\n",
      "jaïnas \\dʒaina\\ -> j,a,ï,n,as \\dʒ,a,i,n,a\\\n",
      "luxe \\lyks\\ -> l,u,xe \\l,y,ks\\\n",
      "momie \\mɔmi\\ -> m,o,m,ie \\m,ɔ,m,i\\\n",
      "oiseaux \\wazo\\ -> o,i,s,eaux \\w,a,z,o\\\n",
      "ondoyés \\ɔ̃dwaje\\ -> on,d,o,y,és \\ɔ̃,d,w,aj,e\\\n",
      "peopliser \\piplize\\ -> p,eo,p,l,i,s,er \\p,i,p,l,i,z,e\\\n",
      "pookie \\puki\\ -> p,oo,k,ie \\p,u,k,i\\\n",
      "rechaterais \\ʁətʃatəʁɛ\\ -> r,e,c,h,a,t,e,r,ais \\ʁ,ə,t,ʃ,a,t,ə,ʁ,ɛ\\\n",
      "solex \\solɛks\\ -> s,o,l,e,x \\s,o,l,ɛ,ks\\\n",
      "Paris \\paʁi\\ -> p,a,r,is \\p,a,ʁ,i\\\n",
      "VPN \\vepeɛn\\ -> v,p,n \\ve,pe,ɛn\\\n"
     ]
    }
   ],
   "source": [
    "essais = [\n",
    "    (\"acéphalobrache\", \"asefalɔbʁak\"),\n",
    "    (\"acquaintance\",\"akwɛ̃tɑ̃s\"),\n",
    "    (\"agoua\",\"aɡwa\"),\n",
    "    (\"bêchâmes\",\"beʃam\"),\n",
    "    (\"caouanne\",\"kawan\"),\n",
    "    (\"designer\",\"dizajnœʁ\"),\n",
    "    (\"désembouteillions\",\"dezɑ̃butɛjɔ̃\"),\n",
    "    (\"disjonctés\",\"diʒɔ̃kte\"),\n",
    "    (\"droitismes\", \"dʁwatism\"),\n",
    "    (\"élégante\", \"eleɡɑ̃t\"),\n",
    "    (\"enarrhas\", \"ɑ̃naʁa\"),\n",
    "    (\"enfutailler\", \"ɑ̃fytɑje\"),\n",
    "    (\"excaverai\", \"ɛkskavəʁe\"),\n",
    "    (\"exemple\", \"ɛɡzɑ̃pl\"),\n",
    "    (\"fashion\",\"faʃœn\"),\n",
    "    (\"khartoumisé\",\"kaʁtumize\"),\n",
    "    (\"hauts\", \"o\"),\n",
    "    ('hauts-fonds','o.fɔ̃'),\n",
    "    (\"html\", \"aʃteɛmɛl\"), #acronyme\n",
    "    (\"intérêt\", \"ɛ̃teʁɛ\"),\n",
    "    (\"intéressant\",\"ɛ̃teʁɛsɑ̃\"),\n",
    "    (\"jaïnas\",\"dʒaina\"),\n",
    "    (\"luxe\",\"lyks\"),\n",
    "    (\"momie\",\"mɔmi\"),\n",
    "    (\"oiseaux\", \"wazo\"),\n",
    "    (\"ondoyés\", \"ɔ̃dwaje\"),\n",
    "    (\"peopliser\",\"piplize\"),\n",
    "    (\"pookie\", \"puki\"),\n",
    "    (\"rechaterais\", \"ʁətʃatəʁɛ\"),\n",
    "    ('solex', 'solɛks'),\n",
    "    ('Paris', 'pa.ʁi'),\n",
    "    ('VPN', 've.pe.ɛn'),\n",
    "    \n",
    "]\n",
    "\n",
    "for essai in essais:\n",
    "  #check_word_pronunciation(essai[0], essai[1].replace('.',''), essai[0].lower().replace('-',''), unit_test=True, verbose0=True, verbose1=False, verbose2=False)\n",
    "  check_word_pronunciation(essai[0], essai[1].replace('.',''), essai[0].lower().replace('-',''), unit_test=True, verbose0=True, verbose1=False, verbose2=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_E7sUaT5bd2U"
   },
   "source": [
    "### Test en masse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1aSsYCmh3J0R",
    "outputId": "61692a02-e47c-498f-e447-dcc83f2d84fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1484043, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "pWuUXTC23K8P",
    "outputId": "6aba893e-bae7-41a9-a89d-8637e495fc60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb mots composés:159290\n",
      "nb mots préfixes:424\n",
      "nb mots noms communs:1292718\n",
      "nb mots noms propres:28581\n",
      "nb mots sigles:1971\n",
      "nb mots autres:1059\n",
      "nb mots TOTAL:1486014\n"
     ]
    }
   ],
   "source": [
    "# trier le dataframe (noms communs, acronymes, noms propres, puis restants)\n",
    "# pour des exemples plus significatifs dans les statistiques\n",
    "df_composés = df[df.Mot.str.match('..*?[\\-\\ ].*?.')].copy()\n",
    "print(\"nb mots composés:%d\" % df_composés.shape[0])\n",
    "\n",
    "df_autres_0 = pd.concat([df, df_composés, df_composés]).drop_duplicates(keep=False)\n",
    "df_préfixes = df_autres_0[df_autres_0.Mot.str.startswith('-')].copy()\n",
    "print(\"nb mots préfixes:%d\" % df_préfixes.shape[0])\n",
    "\n",
    "df_autres_1 = pd.concat([df_autres_0, df_préfixes, df_préfixes]).drop_duplicates(keep=False)\n",
    "df_nc = df_autres_1[df_autres_1.Mot.str.islower()].copy()\n",
    "print(\"nb mots noms communs:%d\" % df_nc.shape[0])\n",
    "\n",
    "df_autres_2 = pd.concat([df_autres_1, df_nc, df_nc]).drop_duplicates(keep=False)\n",
    "df_np = df_autres_2[df_autres_2.Mot.str.istitle()].copy()\n",
    "print(\"nb mots noms propres:%d\" % df_np.shape[0])\n",
    "\n",
    "df_autres_3 = pd.concat([df_autres_2, df_np, df_np]).drop_duplicates(keep=False)\n",
    "df_sigles = df_autres_3[df_autres_3.Mot.str.isupper()].copy()\n",
    "print(\"nb mots sigles:%d\" % df_sigles.shape[0])\n",
    "\n",
    "df_autres_4 = pd.concat([df_autres_3, df_sigles, df_sigles]).drop_duplicates(keep=False)\n",
    "print(\"nb mots autres:%d\" % df_autres_4.shape[0])\n",
    "\n",
    "# mettre dans un ordre augmentant les probabilités de succès des noms composés\n",
    "df_new = pd.concat([df_nc, df_sigles, df_np, df_composés, df_préfixes, df_sigles, df_autres_4], ignore_index=True).copy()\n",
    "print(\"nb mots TOTAL:%d\" % df_new.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "aQ_ek99vrt_y",
    "outputId": "0ec71f7e-8912-4d98-9193-bacf6891c823"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_Code</th>\n",
       "      <th>Warn_Label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1432947</td>\n",
       "      <td>xDSL</td>\n",
       "      <td>iks.de.ɛs‿ɛl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1442217</td>\n",
       "      <td>éSwatini</td>\n",
       "      <td>e.swa.ti.ni</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom propre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1484012</td>\n",
       "      <td>€</td>\n",
       "      <td>ø.ʁo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>symbole</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1484013</td>\n",
       "      <td>℁</td>\n",
       "      <td>o bɔ̃ swɛ̃ də</td>\n",
       "      <td>0.0</td>\n",
       "      <td>préposition</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1484014</td>\n",
       "      <td>∴</td>\n",
       "      <td>mɔʁ‿o.vaʃ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>symbole_num=2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mot  Prononciation  H_aspiré           Type  Pré_valide  \\\n",
       "1432947      xDSL   iks.de.ɛs‿ɛl       0.0            nom         1.0   \n",
       "1442217  éSwatini    e.swa.ti.ni       0.0     nom propre         1.0   \n",
       "1484012         €           ø.ʁo       0.0        symbole         1.0   \n",
       "1484013         ℁  o bɔ̃ swɛ̃ də       0.0    préposition         1.0   \n",
       "1484014         ∴      mɔʁ‿o.vaʃ       0.0  symbole_num=2         1.0   \n",
       "\n",
       "        Warn_Code Warn_Label Plausible  \n",
       "1432947         -          -         ?  \n",
       "1442217         -          -         ?  \n",
       "1484012         -          -         ?  \n",
       "1484013         -          -         ?  \n",
       "1484014         -          -         ?  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_autres_4.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "01jCIjPAhhQp",
    "outputId": "e21472f2-c2e4-443a-e4fc-4e5b78ac271a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1485362, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df_new\n",
    "#df2=df2[df2.Mot.str.istitle()] # ne conserver que les mots commençant par une majuscule puis minuscules\n",
    "#df2=df2[df2.Mot.str.islower()] # ne conserver que les mots entièrement en minuscules (i.e. noms communs)\n",
    "#df2=df2[df2.Mot.str.isupper()] # ne conserver que les mots entièrement en majuscules (i.e. acronymes)#\n",
    "#df2=df2[df2.Mot.str.startswith('x')] # ne conserver que les mots noms communs commençant par ...\n",
    "#df2 = pd.concat([df2, df_composés, df_composés]).drop_duplicates(keep=False) # supprimer les mots composés\n",
    "#df2 = df2[~df2.Mot.str.contains(' ')] # exclure les mots contenant un espace\n",
    "#df2 = df2[~df2.Mot.str.contains('-')] # exclure les mots contenant un tiret\n",
    "\n",
    "df2 = df2[~df2.Mot.str.contains('\\.')] # exclure les mots contenant un point\n",
    "df2 = df2[~df2.Mot.str.contains('/')] # exclure les mots contenant un slash (e.g. copier/coller)\n",
    "\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "JOCz6EX3hhQ0",
    "outputId": "2ef3b62b-3112-4ceb-b3c4-49e0e8cb8892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:1, nb_samples:148536, durée:0:00:41.058744\n",
      "batch:2, nb_samples:297072, durée:0:00:39.065859\n",
      "batch:3, nb_samples:445608, durée:0:00:41.450265\n",
      "batch:4, nb_samples:594144, durée:0:00:39.984475\n",
      "batch:5, nb_samples:742680, durée:0:00:39.328564\n",
      "batch:6, nb_samples:891216, durée:0:00:42.307516\n",
      "batch:7, nb_samples:1039752, durée:0:00:40.559991\n",
      "batch:8, nb_samples:1188288, durée:0:00:41.899520\n",
      "batch:9, nb_samples:1336824, durée:0:01:50.104483\n",
      "batch:10, nb_samples:1485360, durée:0:04:18.208721\n",
      "nb_samples: 1485362  durée de processing du dernier batch: 0:00:00.000480\n",
      "samples=1485362, samples_ok=1473318, samples_ko=12044, very_bad=0, ok%=99.19\n"
     ]
    }
   ],
   "source": [
    "nb_samples=0\n",
    "nb_infos_steps=10\n",
    "nb_samples_steps = int(df2.shape[0]/nb_infos_steps)\n",
    "nb_samples_ok=0\n",
    "nb_samples_ko=0\n",
    "nb_very_bad=0\n",
    "nb_batch=0\n",
    "verbose=False\n",
    "indexes_to_forget = []\n",
    "nb_composés = 0\n",
    "nb_composés_directs_found = 0\n",
    "nb_composés_indirects_found = 0\n",
    "\n",
    "t0 = datetime.datetime.now()\n",
    "for index, row in df2.iterrows():\n",
    "\n",
    "    nb_samples += 1\n",
    "    is_ok = False\n",
    "    is_skipped = False\n",
    "        \n",
    "    if nb_samples >= nb_infos_steps and nb_samples % nb_samples_steps == 0:\n",
    "      nb_batch += 1\n",
    "      t1 = datetime.datetime.now()\n",
    "      durée = t1 - t0\n",
    "      print('batch:%d, nb_samples:%d, durée:%s' % (nb_batch, nb_samples, durée))\n",
    "      t0 = t1\n",
    "\n",
    "    mot = row['Mot']\n",
    "    prononciation = row['Prononciation']\n",
    " \n",
    "    is_composé = False\n",
    "    is_composé_direct = False\n",
    "    if ' ' in row['Mot'] or ',' in row['Mot'] or '-' in row['Mot']:\n",
    "      nb_composés += 1     \n",
    "      is_composé = True\n",
    "        \n",
    "    try:\n",
    "      graphemes = row['Mot'].lower().replace(' ', '').replace('-','').replace(',','')\n",
    "      phonemes = prononciation.replace('(','').replace(')','').replace('‿','').replace('.','').replace(' ','')\n",
    "      is_ok = check_word_pronunciation(mot, phonemes, graphemes, False, False, False, False)\n",
    "          \n",
    "      if is_ok:\n",
    "        if ' ' in row['Mot'] or ',' in row['Mot'] or '-' in row['Mot']:\n",
    "          is_composé_direct = True\n",
    "          nb_composés_directs_found += 1      \n",
    "    \n",
    "    except:\n",
    "      is_ok = False\n",
    "      is_skipped = True \n",
    "      nb_very_bad+=1\n",
    "      # mauvaise lettre ou phoneme, pas la peine d'aller plus loi\n",
    "      # passer au mot suivant\n",
    "\n",
    "    # si la correspondance n'a pas été trouvé, tester si le mot est composé,\n",
    "    # et si oui, tester la correspondance de chaque partie (aka sous-mot)\n",
    "    if not is_ok and not is_skipped:    \n",
    "      graphemes = row['Mot'].lower().replace(',','')\n",
    "      phonemes = prononciation    \n",
    "      separateurs = [' ', '-']\n",
    "      for separateur in separateurs:\n",
    "        if separateur in graphemes[1:-1] :\n",
    "          mots_ = mot.split(separateur)\n",
    "          # si le mot n'est pas un mot composé, l'oubler, et passer à la suite\n",
    "          if len(mots_) <= 1:\n",
    "            continue\n",
    "          for mot_ in mots_:\n",
    "            try:\n",
    "              # récuperer le sous-mot identifiés ainsi que ses différentes prononciations possibles\n",
    "              phonemess_ = df[df.Mot==mot_]['Prononciation'].values\n",
    "              for phonemes_ in phonemess_:\n",
    "                graphemes_ = mot_\n",
    "                phonemes_ = phonemes_.replace('(','').replace(')','').replace('‿','').replace('.','').replace(' ','')\n",
    "                is_ok_ = check_word_pronunciation(mot_, phonemes_, graphemes_, False, False, False, False)\n",
    "                if is_ok_:\n",
    "                    break                    \n",
    "              if is_ok_ == False:\n",
    "                is_ok = False                \n",
    "              else:\n",
    "                is_ok = True\n",
    "                break\n",
    "            except:\n",
    "              is_ok = False\n",
    "            \n",
    "    if is_ok and is_composé:\n",
    "        if not is_composé_direct:\n",
    "            nb_composés_indirects_found += 1\n",
    "    #if not is_ok and is_composé:\n",
    "    #    print('word=%s \\\\\\\\%s\\\\\\\\'% (mot, prononciation))\n",
    "        \n",
    "    if is_ok:\n",
    "      nb_samples_ok += 1\n",
    "      df2.at[index, 'Plausible']='oui'\n",
    "      indexes_to_forget.append(index)\n",
    "    else:\n",
    "      nb_samples_ko += 1\n",
    "      if verbose:\n",
    "        if row['Type'] != 'verbe_flexion':\n",
    "          print('word=%s \\\\\\\\%s\\\\\\\\'% (mot, prononciation))\n",
    "      df2.at[index, 'Plausible']='non'\n",
    "        \n",
    "\n",
    "t1 = datetime.datetime.now()\n",
    "durée = t1 - t0\n",
    "print('nb_samples:', nb_samples, ' durée de processing du dernier batch:', durée)\n",
    "      \n",
    "df2 = df2.drop(indexes_to_forget)\n",
    "\n",
    "if nb_samples > 0:\n",
    "  print('samples=%d, samples_ok=%d, samples_ko=%d, very_bad=%d, ok%%=%.2f' % \\\n",
    "        (nb_samples, nb_samples_ok, nb_samples_ko, nb_very_bad, \\\n",
    "         nb_samples_ok/nb_samples*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_samples: 1292602  durée de processing du dernier batch: 0:00:00.000838\n",
    "#samples=1292602, samples_ok=1279990, samples_ko=12612, very_bad=0 %ok=99.02\n",
    "\n",
    "#samples=1485362, samples_ok=1471019, samples_ko=14343, very_bad=0, ok%=99.03\n",
    "#nb_composés:160151\n",
    "#nb_composés_directs_found:154583\n",
    "#nb_composés_indirects_found:5216\n",
    "#nb_composés_not_found:352\n",
    "\n",
    "#samples=1485362, samples_ok=1468451, samples_ko=16911, very_bad=0, ok%=98.86\n",
    "#nb_composés:160151\n",
    "#nb_composés_directs_found:0\n",
    "#nb_composés_indirects_found:157231\n",
    "#nb_composés_not_found:2920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6X8pia-32RtQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12044, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFgO0o3H4Srh",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_Code</th>\n",
       "      <th>Warn_Label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1485869</td>\n",
       "      <td>Sahaiʔa</td>\n",
       "      <td>sa.haj.a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>prénom_genre=f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>err_phonemes</td>\n",
       "      <td>h</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485872</td>\n",
       "      <td>Selk’nam</td>\n",
       "      <td>sɛlk.nam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485874</td>\n",
       "      <td>TADs</td>\n",
       "      <td>te.a.de</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485960</td>\n",
       "      <td>URNs</td>\n",
       "      <td>y.ɛʁ.ɛn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485961</td>\n",
       "      <td>UpM</td>\n",
       "      <td>y.pe.em</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485972</td>\n",
       "      <td>Vosg’patt</td>\n",
       "      <td>voʒ.pat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485973</td>\n",
       "      <td>WEIs</td>\n",
       "      <td>ˈwaj ou ˈwɛj</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485974</td>\n",
       "      <td>Wuchiaping’ien</td>\n",
       "      <td>wu.tʃja.piŋ.jɛ̃</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485976</td>\n",
       "      <td>XPs</td>\n",
       "      <td>iks.pe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485978</td>\n",
       "      <td>Xi’an</td>\n",
       "      <td>ʃi.an</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom propre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485979</td>\n",
       "      <td>Xi’an</td>\n",
       "      <td>sjan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom propre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485982</td>\n",
       "      <td>YouTubeur</td>\n",
       "      <td>ju.tju.bœʁ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485984</td>\n",
       "      <td>YouTubeurs</td>\n",
       "      <td>ju.tju.bœʁ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485986</td>\n",
       "      <td>YouTubeuse</td>\n",
       "      <td>ju.tju.bøz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485989</td>\n",
       "      <td>YouTubeuses</td>\n",
       "      <td>ju.tju.bøz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485992</td>\n",
       "      <td>d’Ursel</td>\n",
       "      <td>dyʁs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom de famille</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1486004</td>\n",
       "      <td>microSD</td>\n",
       "      <td>s</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1486011</td>\n",
       "      <td>€</td>\n",
       "      <td>ø.ʁo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>symbole</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1486012</td>\n",
       "      <td>℁</td>\n",
       "      <td>o bɔ̃ swɛ̃ də</td>\n",
       "      <td>0.0</td>\n",
       "      <td>préposition</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1486013</td>\n",
       "      <td>∴</td>\n",
       "      <td>mɔʁ‿o.vaʃ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>symbole_num=2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mot    Prononciation  H_aspiré            Type  \\\n",
       "1485869         Sahaiʔa         sa.haj.a       0.0  prénom_genre=f   \n",
       "1485872        Selk’nam         sɛlk.nam       0.0             nom   \n",
       "1485874            TADs          te.a.de       0.0     nom_flexion   \n",
       "1485960            URNs          y.ɛʁ.ɛn       0.0     nom_flexion   \n",
       "1485961             UpM          y.pe.em       0.0             nom   \n",
       "1485972       Vosg’patt          voʒ.pat       0.0             nom   \n",
       "1485973            WEIs     ˈwaj ou ˈwɛj       0.0     nom_flexion   \n",
       "1485974  Wuchiaping’ien  wu.tʃja.piŋ.jɛ̃       0.0             nom   \n",
       "1485976             XPs           iks.pe       0.0     nom_flexion   \n",
       "1485978           Xi’an            ʃi.an       0.0      nom propre   \n",
       "1485979           Xi’an             sjan       0.0      nom propre   \n",
       "1485982       YouTubeur       ju.tju.bœʁ       0.0             nom   \n",
       "1485984      YouTubeurs       ju.tju.bœʁ       0.0     nom_flexion   \n",
       "1485986      YouTubeuse       ju.tju.bøz       0.0     nom_flexion   \n",
       "1485989     YouTubeuses       ju.tju.bøz       0.0     nom_flexion   \n",
       "1485992         d’Ursel             dyʁs       0.0  nom de famille   \n",
       "1486004         microSD                s       0.0             nom   \n",
       "1486011               €             ø.ʁo       0.0         symbole   \n",
       "1486012               ℁    o bɔ̃ swɛ̃ də       0.0     préposition   \n",
       "1486013               ∴        mɔʁ‿o.vaʃ       0.0   symbole_num=2   \n",
       "\n",
       "         Pré_valide     Warn_Code Warn_Label Plausible  \n",
       "1485869         0.0  err_phonemes          h       non  \n",
       "1485872         1.0             -          -       non  \n",
       "1485874         1.0             -          -       non  \n",
       "1485960         1.0             -          -       non  \n",
       "1485961         1.0             -          -       non  \n",
       "1485972         1.0             -          -       non  \n",
       "1485973         1.0             -          -       non  \n",
       "1485974         1.0             -          -       non  \n",
       "1485976         1.0             -          -       non  \n",
       "1485978         1.0             -          -       non  \n",
       "1485979         1.0             -          -       non  \n",
       "1485982         1.0             -          -       non  \n",
       "1485984         1.0             -          -       non  \n",
       "1485986         1.0             -          -       non  \n",
       "1485989         1.0             -          -       non  \n",
       "1485992         1.0             -          -       non  \n",
       "1486004         1.0             -          -       non  \n",
       "1486011         1.0             -          -       non  \n",
       "1486012         1.0             -          -       non  \n",
       "1486013         1.0             -          -       non  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 derniers mot dont la prononciation est détectée comme non plausible\n",
    "df2[df2.Plausible=='non'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kq85BIVx4TCg"
   },
   "outputs": [],
   "source": [
    "# stockage des mots dot les prononciations sont non plausibles \n",
    "# dans un fichier CSV\n",
    "#df2 = df2.drop(columns=['Plausible'])\n",
    "df2.to_csv(\"correspondances_non_trouvées.csv\", index=False, quotechar = '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_Code</th>\n",
       "      <th>Warn_Label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Mot, Prononciation, H_aspiré, Type, Pré_valide, Warn_Code, Warn_Label, Plausible]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.Mot == 'patchworkisa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kG2E5cw6nfT9"
   },
   "source": [
    "###Tests unitaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyMUWuQmd5Lk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]],     phoneme_index=0, grapheme_index=0,     phonemes_hist=[], graphemes_hist=[])\n",
      "trying candidate current phoneme=k\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]], phoneme_index=0, grapheme_index=0) current_phoneme:k\n",
      "current_phoneme:k\n",
      "phoneme \\k\\ matching graphemes [[k]] (last_graphemes:[[koweïtisai]])\n",
      "trying2 current_phoneme \\k\\ and current_graphemes [[k]]\n",
      "\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]],     phoneme_index=1, grapheme_index=1,     phonemes_hist=['k'], graphemes_hist=['k'])\n",
      "trying candidate current phoneme=ɔ\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]], phoneme_index=1, grapheme_index=1) current_phoneme:ɔ\n",
      "current_phoneme:ɔ\n",
      "phoneme \\ɔ\\ matching graphemes [[o]] (last_graphemes:[[oweïtisai]])\n",
      "phoneme \\ɔ\\ matching graphemes [[ow]] (last_graphemes:[[oweïtisai]])\n",
      "trying2 current_phoneme \\ɔ\\ and current_graphemes [[o]]\n",
      "\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]],     phoneme_index=2, grapheme_index=2,     phonemes_hist=['k', 'ɔ'], graphemes_hist=['k', 'o'])\n",
      "trying candidate current phoneme=w\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]], phoneme_index=2, grapheme_index=2) current_phoneme:w\n",
      "current_phoneme:w\n",
      "phoneme \\w\\ matching graphemes [[w]] (last_graphemes:[[weïtisai]])\n",
      "trying2 current_phoneme \\w\\ and current_graphemes [[w]]\n",
      "\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]],     phoneme_index=3, grapheme_index=3,     phonemes_hist=['k', 'ɔ', 'w'], graphemes_hist=['k', 'o', 'w'])\n",
      "trying candidate current phoneme=ɛ\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]], phoneme_index=3, grapheme_index=3) current_phoneme:ɛ\n",
      "current_phoneme:ɛ\n",
      "phoneme \\ɛ\\ matching graphemes [[e]] (last_graphemes:[[eïtisai]])\n",
      "phoneme \\ɛ\\ matching graphemes [[eï]] (last_graphemes:[[eïtisai]])\n",
      "trying2 current_phoneme \\ɛ\\ and current_graphemes [[e]]\n",
      "\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]],     phoneme_index=4, grapheme_index=4,     phonemes_hist=['k', 'ɔ', 'w', 'ɛ'], graphemes_hist=['k', 'o', 'w', 'e'])\n",
      "trying candidate current phoneme=t\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]], phoneme_index=4, grapheme_index=4) current_phoneme:t\n",
      "current_phoneme:t\n",
      "KO0: phonemes=\\kɔwɛtize\\ does not match any grapheme !!!\n",
      "trying2 current_phoneme \\ɛ\\ and current_graphemes [[eï]]\n",
      "\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]],     phoneme_index=4, grapheme_index=5,     phonemes_hist=['k', 'ɔ', 'w', 'ɛ'], graphemes_hist=['k', 'o', 'w', 'eï'])\n",
      "trying candidate current phoneme=t\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]], phoneme_index=4, grapheme_index=5) current_phoneme:t\n",
      "current_phoneme:t\n",
      "phoneme \\t\\ matching graphemes [[t]] (last_graphemes:[[tisai]])\n",
      "trying2 current_phoneme \\t\\ and current_graphemes [[t]]\n",
      "\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]],     phoneme_index=5, grapheme_index=6,     phonemes_hist=['k', 'ɔ', 'w', 'ɛ', 't'], graphemes_hist=['k', 'o', 'w', 'eï', 't'])\n",
      "trying candidate current phoneme=i\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]], phoneme_index=5, grapheme_index=6) current_phoneme:i\n",
      "current_phoneme:i\n",
      "phoneme \\i\\ matching graphemes [[i]] (last_graphemes:[[isai]])\n",
      "phoneme \\i\\ matching graphemes [[is]] (last_graphemes:[[isai]])\n",
      "trying2 current_phoneme \\i\\ and current_graphemes [[i]]\n",
      "\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]],     phoneme_index=6, grapheme_index=7,     phonemes_hist=['k', 'ɔ', 'w', 'ɛ', 't', 'i'], graphemes_hist=['k', 'o', 'w', 'eï', 't', 'i'])\n",
      "trying candidate current phoneme=z\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]], phoneme_index=6, grapheme_index=7) current_phoneme:z\n",
      "current_phoneme:z\n",
      "phoneme \\z\\ matching graphemes [[s]] (last_graphemes:[[sai]])\n",
      "trying2 current_phoneme \\z\\ and current_graphemes [[s]]\n",
      "\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]],     phoneme_index=7, grapheme_index=8,     phonemes_hist=['k', 'ɔ', 'w', 'ɛ', 't', 'i', 'z'], graphemes_hist=['k', 'o', 'w', 'eï', 't', 'i', 's'])\n",
      "trying candidate current phoneme=e\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]], phoneme_index=7, grapheme_index=8) current_phoneme:e\n",
      "current_phoneme:e\n",
      "phoneme \\e\\ matching graphemes [[ai]] (last_graphemes:[[ai]])\n",
      "phoneme \\e\\ matching graphemes [[a]] (last_graphemes:[[ai]])\n",
      "trying2 current_phoneme \\e\\ and current_graphemes [[ai]]\n",
      "\n",
      "process_graphemes(phonemes=\\kɔwɛtize\\, graphemes=[[koweïtisai]],     phoneme_index=8, grapheme_index=10,     phonemes_hist=['k', 'ɔ', 'w', 'ɛ', 't', 'i', 'z', 'e'], graphemes_hist=['k', 'o', 'w', 'eï', 't', 'i', 's', 'ai'])\n",
      "ended ok\n",
      "phonemes_hist2b: ['k', 'ɔ', 'w', 'ɛ', 't', 'i', 'z', 'e']\n",
      "graphemes_hist2b: ['k', 'o', 'w', 'eï', 't', 'i', 's', 'ai']\n",
      "current_phoneme \\e\\ and current_graphemes [[ai]] : worked ok\n",
      "phonemes_hist2b: ['k', 'ɔ', 'w', 'ɛ', 't', 'i', 'z', 'e']\n",
      "graphemes_hist2b: ['k', 'o', 'w', 'eï', 't', 'i', 's', 'ai']\n",
      "current_phoneme \\z\\ and current_graphemes [[s]] : worked ok\n",
      "phonemes_hist2b: ['k', 'ɔ', 'w', 'ɛ', 't', 'i', 'z', 'e']\n",
      "graphemes_hist2b: ['k', 'o', 'w', 'eï', 't', 'i', 's', 'ai']\n",
      "current_phoneme \\i\\ and current_graphemes [[i]] : worked ok\n",
      "phonemes_hist2b: ['k', 'ɔ', 'w', 'ɛ', 't', 'i', 'z', 'e']\n",
      "graphemes_hist2b: ['k', 'o', 'w', 'eï', 't', 'i', 's', 'ai']\n",
      "current_phoneme \\t\\ and current_graphemes [[t]] : worked ok\n",
      "phonemes_hist2b: ['k', 'ɔ', 'w', 'ɛ', 't', 'i', 'z', 'e']\n",
      "graphemes_hist2b: ['k', 'o', 'w', 'eï', 't', 'i', 's', 'ai']\n",
      "current_phoneme \\ɛ\\ and current_graphemes [[eï]] : worked ok\n",
      "phonemes_hist2b: ['k', 'ɔ', 'w', 'ɛ', 't', 'i', 'z', 'e']\n",
      "graphemes_hist2b: ['k', 'o', 'w', 'eï', 't', 'i', 's', 'ai']\n",
      "current_phoneme \\w\\ and current_graphemes [[w]] : worked ok\n",
      "phonemes_hist2b: ['k', 'ɔ', 'w', 'ɛ', 't', 'i', 'z', 'e']\n",
      "graphemes_hist2b: ['k', 'o', 'w', 'eï', 't', 'i', 's', 'ai']\n",
      "current_phoneme \\ɔ\\ and current_graphemes [[o]] : worked ok\n",
      "phonemes_hist2b: ['k', 'ɔ', 'w', 'ɛ', 't', 'i', 'z', 'e']\n",
      "graphemes_hist2b: ['k', 'o', 'w', 'eï', 't', 'i', 's', 'ai']\n",
      "current_phoneme \\k\\ and current_graphemes [[k]] : worked ok\n",
      "koweïtisai \\kɔwɛtize\\ -> k,o,w,eï,t,i,s,ai \\k,ɔ,w,ɛ,t,i,z,e\\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mot et prononciation à tester unitairement\n",
    "graphemes_phonemes='koweïtisai,kɔ.wɛ.ti.ze'\n",
    "\n",
    "# recharger la table de correspondance si nécessaire\n",
    "reload_table = False\n",
    "if reload_table:\n",
    "    phonemes2graphemes = read_table_de_correspondance()\n",
    "    phonemes2graphemes = add_keys(phonemes2graphemes)\n",
    "\n",
    "strings = graphemes_phonemes.split(',')\n",
    "mot = strings[0]\n",
    "graphemes = mot.lower()\n",
    "phonemes = strings[1].replace('(','').replace(')','').replace('‿','').replace('.','').replace(' ','')\n",
    "\n",
    "# nettoyage des strings\n",
    "#graphemes = graphemes.replace(' ','')\n",
    "#graphemes = graphemes.replace('-','')\n",
    "#graphemes = graphemes.replace(\"’\",'')\n",
    "phonemes = phonemes.replace(' ','')\n",
    "phonemes = phonemes.replace('\\\\','')\n",
    "phonemes = phonemes.replace('.','')\n",
    "phonemes = phonemes.replace('‿','')\n",
    "phonemes = phonemes.replace('(','')\n",
    "phonemes = phonemes.replace(')','')\n",
    "\n",
    "# test unitaire\n",
    "check_word_pronunciation(mot, phonemes, graphemes, unit_test=True, verbose0=True, verbose1=True, verbose2=True)\n",
    "#check_word_pronunciation(mot, phonemes, graphemes, unit_test=True, verbose0=False, verbose1=False, verbose2=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "th8Jvzrpk342"
   },
   "source": [
    "## Statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2laCDmzlJJO"
   },
   "outputs": [],
   "source": [
    "# Réaliser les comptages tottax statistiques sur les correspondances \n",
    "# précédemment comptées\n",
    "dfp = make_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBkvDJgyOlj4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonème</th>\n",
       "      <th>graphème</th>\n",
       "      <th>occurences</th>\n",
       "      <th>pourcentage</th>\n",
       "      <th>exemple_1</th>\n",
       "      <th>exemple_2</th>\n",
       "      <th>exemple_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>956</td>\n",
       "      <td>ɡz</td>\n",
       "      <td>x</td>\n",
       "      <td>5146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>actinauxisme</td>\n",
       "      <td>actinauxismes</td>\n",
       "      <td>amphixénose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>957</td>\n",
       "      <td>ɡz</td>\n",
       "      <td>xh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phonème graphème  occurences  pourcentage     exemple_1      exemple_2  \\\n",
       "956      ɡz        x        5146          1.0  actinauxisme  actinauxismes   \n",
       "957      ɡz       xh           0          0.0                                \n",
       "\n",
       "       exemple_3  \n",
       "956  amphixénose  \n",
       "957               "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les statistiques d'un phonème en particulier (ex: \\s\\)\n",
    "phoneme = 'ɡz'\n",
    "#hex(ord('s'))\n",
    "dfp[dfp.phonème == phoneme]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvEujTABtn3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonème</th>\n",
       "      <th>graphème</th>\n",
       "      <th>occurences</th>\n",
       "      <th>pourcentage</th>\n",
       "      <th>exemple_1</th>\n",
       "      <th>exemple_2</th>\n",
       "      <th>exemple_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>956</td>\n",
       "      <td>ɡz</td>\n",
       "      <td>x</td>\n",
       "      <td>5146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>actinauxisme</td>\n",
       "      <td>actinauxismes</td>\n",
       "      <td>amphixénose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>957</td>\n",
       "      <td>ɡz</td>\n",
       "      <td>xh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phonème graphème  occurences  pourcentage     exemple_1      exemple_2  \\\n",
       "956      ɡz        x        5146          1.0  actinauxisme  actinauxismes   \n",
       "957      ɡz       xh           0          0.0                                \n",
       "\n",
       "       exemple_3  \n",
       "956  amphixénose  \n",
       "957               "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp[dfp.phonème == phoneme]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LTLaTRWYJn2r"
   },
   "source": [
    "## Bilan des correspondances non trouvées\n",
    "\n",
    "* Normalement, aucune ligne ne devrait être affichée (si noms communs, noms propres et sigles analysés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Df8fmZunHd7r"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonème</th>\n",
       "      <th>graphème</th>\n",
       "      <th>occurences</th>\n",
       "      <th>pourcentage</th>\n",
       "      <th>exemple_1</th>\n",
       "      <th>exemple_2</th>\n",
       "      <th>exemple_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>ɥ</td>\n",
       "      <td>’hu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>œ̃</td>\n",
       "      <td>Hun</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>œ̃</td>\n",
       "      <td>Huns</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605</td>\n",
       "      <td>œ</td>\n",
       "      <td>ogl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>619</td>\n",
       "      <td>ø</td>\n",
       "      <td>hœ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>627</td>\n",
       "      <td>ø</td>\n",
       "      <td>euent</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>818</td>\n",
       "      <td>ɔ̃</td>\n",
       "      <td>ump</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>ɑ̃</td>\n",
       "      <td>aën</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>916</td>\n",
       "      <td>a</td>\n",
       "      <td>acts</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>944</td>\n",
       "      <td>aj</td>\n",
       "      <td>igh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>957</td>\n",
       "      <td>ɡz</td>\n",
       "      <td>xh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958</td>\n",
       "      <td>ɔɛ</td>\n",
       "      <td>œ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>959</td>\n",
       "      <td>tʃ</td>\n",
       "      <td>ch</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>961</td>\n",
       "      <td>tʃ</td>\n",
       "      <td>œ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phonème graphème  occurences  pourcentage exemple_1 exemple_2 exemple_3\n",
       "380       ɥ      ’hu           0          0.0                              \n",
       "584      œ̃      Hun           0          0.0                              \n",
       "585      œ̃     Huns           0          0.0                              \n",
       "605       œ      ogl           0          0.0                              \n",
       "619       ø       hœ           0          0.0                              \n",
       "627       ø    euent           0          0.0                              \n",
       "818      ɔ̃      ump           0          0.0                              \n",
       "846      ɑ̃      aën           0          0.0                              \n",
       "916       a     acts           0          0.0                              \n",
       "944      aj      igh           0          0.0                              \n",
       "957      ɡz       xh           0          0.0                              \n",
       "958      ɔɛ        œ           0          0.0                              \n",
       "959      tʃ       ch           0          0.0                              \n",
       "961      tʃ        œ           0          0.0                              "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "dfp[dfp.occurences == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzhKNdjjU-9U"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#files.download('phonemes2graphemes.csv')\n",
    "#files.download('correspondances_non_trouvées.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "test_de_plausibité.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
